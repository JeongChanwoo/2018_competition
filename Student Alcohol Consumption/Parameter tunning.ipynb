{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dropped_1 = pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dropped_1 = pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_du_dropped_1= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drop_du_dropped_1= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_du_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drop_du_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "### class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1\n",
    "def logistic_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_logistic = [{'penalty' : ['l2', 'l1'],\n",
    "                      'C' : [1,10,100,1000]}]\n",
    "    \n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(LogisticRegression(), param_logistic, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Init signature: SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "###shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, \n",
    "###random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "def sgd_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_sgd = {\n",
    "                        'loss': ['log', 'hinge'],\n",
    "                        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                        'alpha': [0.01,0.01,0.001, 0.0001]\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(SGDClassifier(), param_sgd, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_knn = {\n",
    "                        'n_neighbors' : [1,3,5,10,30,50], \n",
    "                        'weights' : [\"uniform\", \"distance\"],\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(KNeighborsClassifier(), param_knn, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_nb = {\n",
    "                        'priors' :[None]\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(GaussianNB(), param_nb, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_svc = {\n",
    "                        'C': [0.0001,0.001,0.01,1.0,10.0,100.0],  \n",
    "                        'gamma': ['auto', 0.0001,0.001,0.01,1.0],\n",
    "                        'degree': [1,3,5],  # integer valued parameter\n",
    "                        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(svm.SVC(), param_svc, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsvc_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_lsvc = {\n",
    "                       'C': [0.000001, 0.00001,0.0001,0.001,0.01,1,10,100,1000]\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(svm.LinearSVC(max_iter=10000), param_lsvc, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decsiontree_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_dt = {\n",
    "                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "                        \"min_samples_split\": [2, 10, 20],\n",
    "                        \"max_depth\": [None, 2, 5, 10],\n",
    "                        \"min_samples_leaf\": [1, 5, 10],\n",
    "                        \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), param_dt, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_rt = {\n",
    "                    'min_samples_leaf': range(1, 5, 2),\n",
    "                      'max_features': range(1, 6, 2),\n",
    "                      'n_estimators': range(50, 250, 50)\n",
    "                        }\n",
    "\n",
    "    scores = ['accuracy', 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(RandomForestClassifier(), param_rt, cv=5,\n",
    "        scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "#     return clf.cv_results_['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_dropped_1 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.710 (+/-0.086) for {'penalty': 'l2', 'C': 1}\n",
      "0.713 (+/-0.076) for {'penalty': 'l1', 'C': 1}\n",
      "0.709 (+/-0.077) for {'penalty': 'l2', 'C': 10}\n",
      "0.711 (+/-0.078) for {'penalty': 'l1', 'C': 10}\n",
      "0.713 (+/-0.072) for {'penalty': 'l2', 'C': 100}\n",
      "0.713 (+/-0.072) for {'penalty': 'l1', 'C': 100}\n",
      "0.713 (+/-0.072) for {'penalty': 'l2', 'C': 1000}\n",
      "0.713 (+/-0.072) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       122\n",
      "          1       0.65      0.61      0.63        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.676 (+/-0.098) for {'penalty': 'l2', 'C': 1}\n",
      "0.681 (+/-0.080) for {'penalty': 'l1', 'C': 1}\n",
      "0.676 (+/-0.087) for {'penalty': 'l2', 'C': 10}\n",
      "0.680 (+/-0.088) for {'penalty': 'l1', 'C': 10}\n",
      "0.681 (+/-0.084) for {'penalty': 'l2', 'C': 100}\n",
      "0.681 (+/-0.084) for {'penalty': 'l1', 'C': 100}\n",
      "0.681 (+/-0.084) for {'penalty': 'l2', 'C': 1000}\n",
      "0.681 (+/-0.084) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74       122\n",
      "          1       0.64      0.61      0.62        87\n",
      "\n",
      "avg / total       0.69      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.765 (+/-0.078) for {'penalty': 'l2', 'C': 1}\n",
      "0.771 (+/-0.078) for {'penalty': 'l1', 'C': 1}\n",
      "0.765 (+/-0.078) for {'penalty': 'l2', 'C': 10}\n",
      "0.766 (+/-0.079) for {'penalty': 'l1', 'C': 10}\n",
      "0.765 (+/-0.079) for {'penalty': 'l2', 'C': 100}\n",
      "0.765 (+/-0.079) for {'penalty': 'l1', 'C': 100}\n",
      "0.765 (+/-0.079) for {'penalty': 'l2', 'C': 1000}\n",
      "0.765 (+/-0.079) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       122\n",
      "          1       0.65      0.61      0.63        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.652 (+/-0.143) for {'penalty': 'l2', 'C': 1}\n",
      "0.660 (+/-0.121) for {'penalty': 'l1', 'C': 1}\n",
      "0.657 (+/-0.144) for {'penalty': 'l2', 'C': 10}\n",
      "0.662 (+/-0.147) for {'penalty': 'l1', 'C': 10}\n",
      "0.662 (+/-0.148) for {'penalty': 'l2', 'C': 100}\n",
      "0.662 (+/-0.148) for {'penalty': 'l1', 'C': 100}\n",
      "0.662 (+/-0.148) for {'penalty': 'l2', 'C': 1000}\n",
      "0.662 (+/-0.148) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74       122\n",
      "          1       0.64      0.61      0.62        87\n",
      "\n",
      "avg / total       0.69      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.707 (+/-0.125) for {'penalty': 'l2', 'C': 1}\n",
      "0.709 (+/-0.131) for {'penalty': 'l1', 'C': 1}\n",
      "0.705 (+/-0.134) for {'penalty': 'l2', 'C': 10}\n",
      "0.707 (+/-0.134) for {'penalty': 'l1', 'C': 10}\n",
      "0.708 (+/-0.128) for {'penalty': 'l2', 'C': 100}\n",
      "0.708 (+/-0.128) for {'penalty': 'l1', 'C': 100}\n",
      "0.708 (+/-0.128) for {'penalty': 'l2', 'C': 1000}\n",
      "0.708 (+/-0.128) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       122\n",
      "          1       0.65      0.61      0.63        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.679 (+/-0.018) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.672 (+/-0.104) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.704 (+/-0.072) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.686 (+/-0.074) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.668 (+/-0.063) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.684 (+/-0.051) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.681 (+/-0.043) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.662 (+/-0.073) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.685 (+/-0.051) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.661 (+/-0.029) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.638 (+/-0.122) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.673 (+/-0.063) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.685 (+/-0.077) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.607 (+/-0.097) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.668 (+/-0.139) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.662 (+/-0.072) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.634 (+/-0.098) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.661 (+/-0.050) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.625 (+/-0.071) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.630 (+/-0.148) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.599 (+/-0.061) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.668 (+/-0.050) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.601 (+/-0.102) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.601 (+/-0.110) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.73       122\n",
      "          1       0.62      0.61      0.62        87\n",
      "\n",
      "avg / total       0.68      0.68      0.68       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.640 (+/-0.080) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.520 (+/-0.262) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.645 (+/-0.073) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.594 (+/-0.194) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.624 (+/-0.110) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.597 (+/-0.170) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.618 (+/-0.094) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.559 (+/-0.213) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.558 (+/-0.205) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.647 (+/-0.110) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.590 (+/-0.139) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.643 (+/-0.078) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.654 (+/-0.130) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.622 (+/-0.214) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.565 (+/-0.292) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.663 (+/-0.118) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.624 (+/-0.095) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.652 (+/-0.102) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.579 (+/-0.121) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.572 (+/-0.260) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.595 (+/-0.178) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.657 (+/-0.096) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.597 (+/-0.121) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.539 (+/-0.255) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.81      0.76       122\n",
      "          1       0.67      0.53      0.59        87\n",
      "\n",
      "avg / total       0.69      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.739 (+/-0.072) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.733 (+/-0.089) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.758 (+/-0.076) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.763 (+/-0.070) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.743 (+/-0.107) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.768 (+/-0.065) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.753 (+/-0.051) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.743 (+/-0.097) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.754 (+/-0.074) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.764 (+/-0.074) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.744 (+/-0.108) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.747 (+/-0.074) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.737 (+/-0.052) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.719 (+/-0.157) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.747 (+/-0.103) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.736 (+/-0.074) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.729 (+/-0.114) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.690 (+/-0.105) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.729 (+/-0.064) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.697 (+/-0.070) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.750 (+/-0.067) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.731 (+/-0.109) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.715 (+/-0.091) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.737 (+/-0.054) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78       122\n",
      "          1       0.72      0.53      0.61        87\n",
      "\n",
      "avg / total       0.72      0.72      0.71       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.554 (+/-0.118) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.763 (+/-0.207) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.614 (+/-0.311) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.582 (+/-0.146) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.716 (+/-0.360) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.740 (+/-0.191) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.546 (+/-0.148) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.570 (+/-0.268) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.649 (+/-0.213) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.681 (+/-0.209) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.694 (+/-0.358) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.544 (+/-0.328) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.629 (+/-0.350) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.642 (+/-0.306) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.392 (+/-0.271) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.616 (+/-0.432) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.544 (+/-0.326) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.536 (+/-0.386) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.717 (+/-0.205) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.763 (+/-0.157) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.642 (+/-0.478) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.623 (+/-0.225) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.667 (+/-0.494) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.621 (+/-0.241) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.36      0.49       122\n",
      "          1       0.48      0.83      0.61        87\n",
      "\n",
      "avg / total       0.64      0.56      0.54       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.691 (+/-0.111) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.719 (+/-0.090) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.680 (+/-0.176) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.731 (+/-0.189) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.698 (+/-0.249) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.669 (+/-0.184) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.716 (+/-0.070) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.686 (+/-0.134) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.764 (+/-0.131) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.647 (+/-0.185) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.677 (+/-0.244) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.725 (+/-0.179) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.662 (+/-0.158) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.732 (+/-0.293) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.663 (+/-0.236) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.715 (+/-0.177) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.605 (+/-0.268) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.686 (+/-0.410) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.657 (+/-0.124) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.572 (+/-0.204) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.588 (+/-0.067) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.637 (+/-0.140) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.708 (+/-0.135) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.640 (+/-0.349) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.84      0.77       122\n",
      "          1       0.70      0.53      0.60        87\n",
      "\n",
      "avg / total       0.71      0.71      0.70       209\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.692 (+/-0.014) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.692 (+/-0.014) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.657 (+/-0.037) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.678 (+/-0.040) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.632 (+/-0.041) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.661 (+/-0.026) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.625 (+/-0.057) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.667 (+/-0.038) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.630 (+/-0.033) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.649 (+/-0.037) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.636 (+/-0.055) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.659 (+/-0.035) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.67      0.72       122\n",
      "          1       0.61      0.71      0.66        87\n",
      "\n",
      "avg / total       0.70      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.660 (+/-0.037) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.660 (+/-0.037) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.605 (+/-0.052) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.624 (+/-0.043) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.580 (+/-0.051) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.609 (+/-0.035) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.520 (+/-0.084) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.616 (+/-0.036) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.522 (+/-0.048) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.569 (+/-0.042) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.527 (+/-0.055) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.565 (+/-0.035) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.67      0.72       122\n",
      "          1       0.61      0.71      0.66        87\n",
      "\n",
      "avg / total       0.70      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.689 (+/-0.017) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.689 (+/-0.017) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.671 (+/-0.028) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.729 (+/-0.016) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.654 (+/-0.023) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.710 (+/-0.016) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.661 (+/-0.048) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.704 (+/-0.039) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.659 (+/-0.072) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.684 (+/-0.066) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.659 (+/-0.100) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.678 (+/-0.093) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.73      0.74       122\n",
      "          1       0.64      0.67      0.65        87\n",
      "\n",
      "avg / total       0.71      0.70      0.70       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.644 (+/-0.084) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.644 (+/-0.084) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.565 (+/-0.077) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.575 (+/-0.065) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.546 (+/-0.062) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.570 (+/-0.052) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.438 (+/-0.082) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.575 (+/-0.050) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.436 (+/-0.049) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.497 (+/-0.039) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.436 (+/-0.046) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.477 (+/-0.039) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.67      0.72       122\n",
      "          1       0.61      0.71      0.66        87\n",
      "\n",
      "avg / total       0.70      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.678 (+/-0.025) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.678 (+/-0.025) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.652 (+/-0.050) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.684 (+/-0.066) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.619 (+/-0.056) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.656 (+/-0.039) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.641 (+/-0.085) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.665 (+/-0.060) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.653 (+/-0.056) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.664 (+/-0.063) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.669 (+/-0.109) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.695 (+/-0.078) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.74      0.71       122\n",
      "          1       0.59      0.54      0.57        87\n",
      "\n",
      "avg / total       0.65      0.66      0.65       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.628 (+/-0.088) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65       122\n",
      "          1       0.53      0.61      0.57        87\n",
      "\n",
      "avg / total       0.62      0.61      0.62       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.593 (+/-0.084) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65       122\n",
      "          1       0.53      0.61      0.57        87\n",
      "\n",
      "avg / total       0.62      0.61      0.62       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.669 (+/-0.098) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65       122\n",
      "          1       0.53      0.61      0.57        87\n",
      "\n",
      "avg / total       0.62      0.61      0.62       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.582 (+/-0.075) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65       122\n",
      "          1       0.53      0.61      0.57        87\n",
      "\n",
      "avg / total       0.62      0.61      0.62       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.605 (+/-0.110) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.61      0.65       122\n",
      "          1       0.53      0.61      0.57        87\n",
      "\n",
      "avg / total       0.62      0.61      0.62       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naivebayes_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)\n",
    "\n",
    "###상당히 오래걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.030) for {'C': 1e-06}\n",
      "0.552 (+/-0.047) for {'C': 1e-05}\n",
      "0.575 (+/-0.046) for {'C': 0.0001}\n",
      "0.660 (+/-0.058) for {'C': 0.001}\n",
      "0.696 (+/-0.055) for {'C': 0.01}\n",
      "0.716 (+/-0.075) for {'C': 1}\n",
      "0.717 (+/-0.076) for {'C': 10}\n",
      "0.680 (+/-0.097) for {'C': 100}\n",
      "0.602 (+/-0.124) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.78      0.76       122\n",
      "          1       0.67      0.62      0.64        87\n",
      "\n",
      "avg / total       0.71      0.71      0.71       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.128 (+/-0.042) for {'C': 1e-06}\n",
      "0.183 (+/-0.074) for {'C': 1e-05}\n",
      "0.366 (+/-0.081) for {'C': 0.0001}\n",
      "0.578 (+/-0.067) for {'C': 0.001}\n",
      "0.645 (+/-0.066) for {'C': 0.01}\n",
      "0.683 (+/-0.085) for {'C': 1}\n",
      "0.683 (+/-0.085) for {'C': 10}\n",
      "0.654 (+/-0.088) for {'C': 100}\n",
      "0.563 (+/-0.185) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75       122\n",
      "          1       0.65      0.62      0.64        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.594 (+/-0.130) for {'C': 1e-06}\n",
      "0.602 (+/-0.131) for {'C': 1e-05}\n",
      "0.637 (+/-0.128) for {'C': 0.0001}\n",
      "0.699 (+/-0.084) for {'C': 0.001}\n",
      "0.752 (+/-0.074) for {'C': 0.01}\n",
      "0.766 (+/-0.077) for {'C': 1}\n",
      "0.765 (+/-0.076) for {'C': 10}\n",
      "0.771 (+/-0.062) for {'C': 100}\n",
      "0.706 (+/-0.150) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.73      0.73       122\n",
      "          1       0.62      0.63      0.63        87\n",
      "\n",
      "avg / total       0.69      0.69      0.69       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.072 (+/-0.026) for {'C': 1e-06}\n",
      "0.108 (+/-0.045) for {'C': 1e-05}\n",
      "0.265 (+/-0.081) for {'C': 0.0001}\n",
      "0.503 (+/-0.077) for {'C': 0.001}\n",
      "0.595 (+/-0.080) for {'C': 0.01}\n",
      "0.660 (+/-0.128) for {'C': 1}\n",
      "0.660 (+/-0.128) for {'C': 10}\n",
      "0.634 (+/-0.253) for {'C': 100}\n",
      "0.479 (+/-0.543) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75       122\n",
      "          1       0.65      0.62      0.64        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.650 (+/-0.412) for {'C': 1e-06}\n",
      "0.622 (+/-0.311) for {'C': 1e-05}\n",
      "0.603 (+/-0.119) for {'C': 0.0001}\n",
      "0.685 (+/-0.103) for {'C': 0.001}\n",
      "0.706 (+/-0.086) for {'C': 0.01}\n",
      "0.713 (+/-0.118) for {'C': 1}\n",
      "0.715 (+/-0.115) for {'C': 10}\n",
      "0.695 (+/-0.124) for {'C': 100}\n",
      "0.633 (+/-0.146) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75       122\n",
      "          1       0.65      0.62      0.64        87\n",
      "\n",
      "avg / total       0.70      0.70      0.70       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvc_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.696 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.657 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.640 (+/-0.064) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.644 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.638 (+/-0.068) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.649 (+/-0.078) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.671 (+/-0.057) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.674 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.065) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.673 (+/-0.069) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.674 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.674 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.665 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.074) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.665 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.684 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.685 (+/-0.089) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.679 (+/-0.068) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.671 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.671 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.661 (+/-0.019) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.038) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.678 (+/-0.053) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.672 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.679 (+/-0.070) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.678 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.681 (+/-0.060) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.672 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.669 (+/-0.048) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.674 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.673 (+/-0.069) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.673 (+/-0.069) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.665 (+/-0.071) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.665 (+/-0.071) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.665 (+/-0.071) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.683 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.683 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.681 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.681 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.673 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.669 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.691 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.640 (+/-0.070) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.647 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.634 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.650 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.665 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.665 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.067) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.668 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.673 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.065) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.673 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.674 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.673 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.665 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.665 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.666 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.683 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.683 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.679 (+/-0.068) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.671 (+/-0.067) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.669 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.671 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.669 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.710 (+/-0.034) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.686 (+/-0.050) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.030) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.078) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.669 (+/-0.070) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.650 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.653 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.657 (+/-0.056) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.666 (+/-0.041) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.666 (+/-0.041) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.033) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.033) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.033) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.665 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.669 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.674 (+/-0.037) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.671 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.668 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.668 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.666 (+/-0.032) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.659 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.659 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.659 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.635 (+/-0.036) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.033) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.655 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.672 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.052) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.068) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.053) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.055) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.666 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.666 (+/-0.041) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.666 (+/-0.041) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.668 (+/-0.033) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.033) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.033) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.663 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.675 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.679 (+/-0.044) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.671 (+/-0.030) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.050) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.666 (+/-0.032) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.665 (+/-0.044) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.036) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.044) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.687 (+/-0.055) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.681 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.681 (+/-0.052) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.666 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.088) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.654 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.654 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.040) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.663 (+/-0.040) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.668 (+/-0.033) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.033) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.033) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.663 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.663 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.669 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.675 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.033) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.666 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.666 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.666 (+/-0.032) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.659 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.659 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.659 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.80      0.79       122\n",
      "          1       0.71      0.67      0.69        87\n",
      "\n",
      "avg / total       0.74      0.75      0.75       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.660 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.623 (+/-0.135) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.593 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.600 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.091) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.601 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.625 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.621 (+/-0.101) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.585 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.585 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.587 (+/-0.109) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.584 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.594 (+/-0.131) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.579 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.579 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.640 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.633 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.631 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.637 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.632 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.632 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.575 (+/-0.057) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.048) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.605 (+/-0.089) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.631 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.632 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.117) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.632 (+/-0.120) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.626 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.622 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.627 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.623 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.583 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.583 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.100) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.587 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.584 (+/-0.107) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.594 (+/-0.131) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.577 (+/-0.117) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.579 (+/-0.121) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.121) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.633 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.639 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.638 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.640 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.631 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.632 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.633 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.632 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.128) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.601 (+/-0.167) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.598 (+/-0.101) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.603 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.604 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.618 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.626 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.573 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.585 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.585 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.584 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.587 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.594 (+/-0.131) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.579 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.579 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.640 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.631 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.637 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.634 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.685 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.077) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.653 (+/-0.021) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.635 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.636 (+/-0.088) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.635 (+/-0.054) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.632 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.634 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.627 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.557 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.552 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.557 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.081) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.553 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.552 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.554 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.552 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.588 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.609 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.604 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.618 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.613 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.613 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.618 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.620 (+/-0.077) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.616 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.465 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.594 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.610 (+/-0.081) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.625 (+/-0.131) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.627 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.621 (+/-0.111) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.626 (+/-0.117) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.627 (+/-0.120) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.623 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.626 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.627 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.627 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.543 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.552 (+/-0.082) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.557 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.555 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.552 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.552 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.554 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.606 (+/-0.100) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.608 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.605 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.625 (+/-0.116) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.625 (+/-0.116) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.614 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.619 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.619 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.621 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.642 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.040) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.633 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.639 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.628 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.584 (+/-0.047) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.557 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.080) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.551 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.543 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.557 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.553 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.554 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.554 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.552 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.102) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.601 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.604 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.618 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.618 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.613 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.620 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.620 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.618 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.78      0.77       122\n",
      "          1       0.68      0.66      0.67        87\n",
      "\n",
      "avg / total       0.73      0.73      0.73       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.699 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.699 (+/-0.132) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.701 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.683 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.683 (+/-0.092) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.696 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.696 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.694 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.694 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.064) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.065) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.065) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.715 (+/-0.064) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.712 (+/-0.068) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.706 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.707 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.700 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.702 (+/-0.097) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.702 (+/-0.097) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.702 (+/-0.097) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.672 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.693 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.060) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.708 (+/-0.068) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.719 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.716 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.712 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.712 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.714 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.715 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.714 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.714 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.713 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.716 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.711 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.716 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.715 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.685 (+/-0.133) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.695 (+/-0.136) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.699 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.688 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.694 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.692 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.693 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.691 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.695 (+/-0.089) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.686 (+/-0.042) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.064) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.065) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.065) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.715 (+/-0.064) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.714 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.706 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.705 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.700 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.701 (+/-0.095) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.702 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.702 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.026) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.712 (+/-0.025) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.721 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.705 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.703 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.711 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.703 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.703 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.692 (+/-0.048) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.692 (+/-0.048) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.700 (+/-0.044) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.052) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.052) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.702 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.702 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.702 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.693 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.695 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.694 (+/-0.069) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.077) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.077) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.703 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.705 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.705 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.705 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.070) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.688 (+/-0.063) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.692 (+/-0.069) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.725 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.722 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.719 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.711 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.712 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.710 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.712 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.709 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.691 (+/-0.048) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.691 (+/-0.048) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.699 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.052) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.052) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.703 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.701 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.701 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.702 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.701 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.715 (+/-0.066) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.705 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.698 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.706 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.705 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.705 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.705 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.717 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.723 (+/-0.029) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.708 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.707 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.706 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.705 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.705 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.697 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.692 (+/-0.048) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.692 (+/-0.048) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.700 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.053) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.052) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.701 (+/-0.046) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.701 (+/-0.046) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.702 (+/-0.046) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.691 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.695 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.694 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.701 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.701 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.703 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.705 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.705 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.705 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.77       122\n",
      "          1       0.70      0.44      0.54        87\n",
      "\n",
      "avg / total       0.69      0.69      0.67       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.642 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.595 (+/-0.180) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.572 (+/-0.152) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.590 (+/-0.143) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.134) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.577 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.595 (+/-0.169) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.149) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.593 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.500 (+/-0.190) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.495 (+/-0.185) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.505 (+/-0.187) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.505 (+/-0.187) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.531 (+/-0.240) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.500 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.500 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.503 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.598 (+/-0.206) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.608 (+/-0.185) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.134) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.601 (+/-0.135) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.603 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.606 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.616 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.616 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.616 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.497 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.521 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.557 (+/-0.177) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.621 (+/-0.243) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.598 (+/-0.255) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.593 (+/-0.238) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.608 (+/-0.229) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.619 (+/-0.224) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.608 (+/-0.200) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.598 (+/-0.199) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.598 (+/-0.203) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.601 (+/-0.198) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.500 (+/-0.190) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.500 (+/-0.190) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.495 (+/-0.185) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.505 (+/-0.187) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.188) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.528 (+/-0.242) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.500 (+/-0.189) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.189) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.500 (+/-0.189) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.598 (+/-0.209) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.603 (+/-0.195) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.572 (+/-0.194) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.611 (+/-0.144) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.603 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.608 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.616 (+/-0.107) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.608 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.611 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.572 (+/-0.207) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.570 (+/-0.157) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.577 (+/-0.167) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.582 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.582 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.601 (+/-0.158) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.151) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.593 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.503 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.497 (+/-0.184) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.505 (+/-0.187) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.188) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.531 (+/-0.240) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.500 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.500 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.608 (+/-0.185) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.608 (+/-0.185) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.588 (+/-0.134) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.601 (+/-0.135) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.601 (+/-0.135) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.598 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.616 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.616 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.608 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.663 (+/-0.130) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.647 (+/-0.033) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.642 (+/-0.122) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.116) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.631 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.631 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.637 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.430 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.430 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.443 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.425 (+/-0.109) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.454 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.448 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.451 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.454 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.451 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.516 (+/-0.169) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.547 (+/-0.202) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.554 (+/-0.220) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.580 (+/-0.225) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.580 (+/-0.225) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.580 (+/-0.196) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.603 (+/-0.145) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.603 (+/-0.145) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.595 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.358 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.551 (+/-0.086) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.588 (+/-0.163) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.603 (+/-0.225) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.595 (+/-0.232) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.593 (+/-0.223) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.606 (+/-0.200) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.608 (+/-0.215) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.598 (+/-0.192) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.616 (+/-0.171) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.613 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.611 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.459 (+/-0.116) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.459 (+/-0.116) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.443 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.425 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.425 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.446 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.454 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.454 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.451 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.549 (+/-0.196) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.547 (+/-0.202) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.575 (+/-0.178) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.595 (+/-0.215) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.593 (+/-0.208) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.583 (+/-0.203) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.595 (+/-0.148) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.601 (+/-0.141) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.601 (+/-0.141) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.644 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.613 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.637 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.624 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.626 (+/-0.065) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.644 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.634 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.642 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.515 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.459 (+/-0.116) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.430 (+/-0.105) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.443 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.425 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.425 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.448 (+/-0.113) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.454 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.454 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.451 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.508 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.549 (+/-0.196) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.575 (+/-0.178) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.595 (+/-0.200) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.580 (+/-0.225) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.580 (+/-0.196) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.603 (+/-0.145) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.603 (+/-0.145) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.603 (+/-0.145) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.76      0.78       122\n",
      "          1       0.68      0.72      0.70        87\n",
      "\n",
      "avg / total       0.75      0.75      0.75       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.677 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.651 (+/-0.152) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.623 (+/-0.060) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.620 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.625 (+/-0.131) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.626 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.650 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.655 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.653 (+/-0.077) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.732 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.731 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.730 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.729 (+/-0.162) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.730 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.167) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.709 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.709 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.710 (+/-0.157) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.689 (+/-0.155) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.697 (+/-0.178) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.188) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.685 (+/-0.145) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.682 (+/-0.136) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.663 (+/-0.151) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.666 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.692 (+/-0.072) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.066) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.677 (+/-0.117) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.682 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.660 (+/-0.120) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.134) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.676 (+/-0.117) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.667 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.665 (+/-0.084) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.731 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.732 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.729 (+/-0.162) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.729 (+/-0.162) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.730 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.167) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.710 (+/-0.157) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.709 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.709 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.684 (+/-0.131) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.684 (+/-0.131) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.709 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.686 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.678 (+/-0.119) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.670 (+/-0.122) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.655 (+/-0.130) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.665 (+/-0.155) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.655 (+/-0.130) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.670 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.630 (+/-0.117) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.625 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.615 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.630 (+/-0.135) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.637 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.060) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.652 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.653 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.732 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.732 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.729 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.729 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.729 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.167) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.709 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.710 (+/-0.157) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.710 (+/-0.157) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.689 (+/-0.155) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.697 (+/-0.178) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.699 (+/-0.174) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.682 (+/-0.136) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.683 (+/-0.136) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.676 (+/-0.153) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.663 (+/-0.151) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.663 (+/-0.151) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.696 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.676 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.032) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.642 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.658 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.621 (+/-0.054) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.620 (+/-0.056) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.626 (+/-0.050) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.720 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.720 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.768 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.768 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.741 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.730 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.729 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.729 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.712 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.709 (+/-0.158) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.672 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.658 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.659 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.650 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.650 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.759 (+/-0.199) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.643 (+/-0.053) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.659 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.663 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.085) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.092) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.100) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.647 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.642 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.650 (+/-0.085) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.720 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.750 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.768 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.768 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.091) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.729 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.730 (+/-0.107) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.730 (+/-0.107) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.714 (+/-0.160) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.703 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.700 (+/-0.168) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.666 (+/-0.060) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.666 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.685 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.663 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.642 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.653 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.644 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.631 (+/-0.056) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.055) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.623 (+/-0.060) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.680 (+/-0.062) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.750 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.750 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.768 (+/-0.105) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.768 (+/-0.105) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.729 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.729 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.730 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.151) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.706 (+/-0.146) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.702 (+/-0.192) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.658 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.658 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.067) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.650 (+/-0.102) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.650 (+/-0.102) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.84      0.77       122\n",
      "          1       0.70      0.52      0.60        87\n",
      "\n",
      "avg / total       0.71      0.71      0.70       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decsiontree_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.749 (+/-0.038) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.812 (+/-0.051) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.787 (+/-0.043) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.787 (+/-0.051) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.705 (+/-0.067) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.726 (+/-0.069) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.715 (+/-0.032) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.728 (+/-0.034) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.754 (+/-0.049) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.766 (+/-0.063) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.774 (+/-0.072) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.787 (+/-0.064) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.741 (+/-0.040) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.743 (+/-0.078) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.741 (+/-0.061) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.739 (+/-0.050) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.751 (+/-0.075) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.775 (+/-0.071) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.780 (+/-0.078) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.784 (+/-0.066) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.725 (+/-0.082) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.739 (+/-0.048) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.745 (+/-0.089) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.746 (+/-0.082) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.85      0.84       122\n",
      "          1       0.79      0.76      0.77        87\n",
      "\n",
      "avg / total       0.81      0.81      0.81       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.731 (+/-0.024) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.746 (+/-0.068) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.755 (+/-0.043) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.756 (+/-0.044) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.610 (+/-0.098) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.646 (+/-0.071) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.639 (+/-0.045) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.638 (+/-0.053) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.734 (+/-0.093) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.726 (+/-0.080) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.739 (+/-0.089) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.744 (+/-0.095) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.667 (+/-0.077) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.671 (+/-0.077) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.684 (+/-0.055) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.679 (+/-0.073) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.716 (+/-0.091) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.729 (+/-0.093) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.729 (+/-0.082) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.727 (+/-0.088) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.690 (+/-0.094) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.688 (+/-0.080) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.705 (+/-0.072) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.697 (+/-0.095) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       122\n",
      "          1       0.83      0.74      0.78        87\n",
      "\n",
      "avg / total       0.83      0.83      0.83       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.858 (+/-0.054) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.867 (+/-0.053) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.874 (+/-0.059) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.880 (+/-0.049) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.779 (+/-0.089) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.784 (+/-0.054) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.797 (+/-0.074) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.797 (+/-0.097) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.846 (+/-0.072) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.851 (+/-0.091) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.851 (+/-0.094) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.856 (+/-0.070) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.797 (+/-0.084) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.800 (+/-0.089) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.810 (+/-0.106) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.806 (+/-0.110) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.833 (+/-0.077) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.842 (+/-0.079) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.844 (+/-0.081) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.848 (+/-0.090) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.784 (+/-0.082) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.800 (+/-0.088) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.809 (+/-0.092) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.811 (+/-0.105) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85       122\n",
      "          1       0.81      0.75      0.78        87\n",
      "\n",
      "avg / total       0.82      0.82      0.82       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.665 (+/-0.058) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.675 (+/-0.098) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.667 (+/-0.082) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.675 (+/-0.064) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.546 (+/-0.133) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.554 (+/-0.066) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.536 (+/-0.076) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.526 (+/-0.078) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.639 (+/-0.056) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.670 (+/-0.078) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.668 (+/-0.083) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.668 (+/-0.061) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.626 (+/-0.148) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.603 (+/-0.140) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.595 (+/-0.117) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.601 (+/-0.109) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.637 (+/-0.103) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.655 (+/-0.122) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.680 (+/-0.092) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.680 (+/-0.122) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.611 (+/-0.110) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.616 (+/-0.101) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.621 (+/-0.085) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.616 (+/-0.120) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.83       122\n",
      "          1       0.77      0.70      0.73        87\n",
      "\n",
      "avg / total       0.79      0.79      0.79       209\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.819 (+/-0.094) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.869 (+/-0.073) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.839 (+/-0.049) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.845 (+/-0.063) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.745 (+/-0.142) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.804 (+/-0.084) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.814 (+/-0.075) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.794 (+/-0.112) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.798 (+/-0.099) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.832 (+/-0.091) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.803 (+/-0.086) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.817 (+/-0.053) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.780 (+/-0.083) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.788 (+/-0.101) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.805 (+/-0.098) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.788 (+/-0.073) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.797 (+/-0.027) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.823 (+/-0.087) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.806 (+/-0.101) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.823 (+/-0.060) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.786 (+/-0.096) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.798 (+/-0.092) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.805 (+/-0.111) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.795 (+/-0.108) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       122\n",
      "          1       0.78      0.71      0.74        87\n",
      "\n",
      "avg / total       0.79      0.79      0.79       209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomforest_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_drop_du_dropped_1 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.694 (+/-0.063) for {'penalty': 'l2', 'C': 1}\n",
      "0.699 (+/-0.070) for {'penalty': 'l1', 'C': 1}\n",
      "0.698 (+/-0.062) for {'penalty': 'l2', 'C': 10}\n",
      "0.696 (+/-0.062) for {'penalty': 'l1', 'C': 10}\n",
      "0.692 (+/-0.055) for {'penalty': 'l2', 'C': 100}\n",
      "0.692 (+/-0.055) for {'penalty': 'l1', 'C': 100}\n",
      "0.692 (+/-0.055) for {'penalty': 'l2', 'C': 1000}\n",
      "0.692 (+/-0.055) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.83      0.75        65\n",
      "          1       0.80      0.63      0.70        68\n",
      "\n",
      "avg / total       0.74      0.73      0.73       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.636 (+/-0.060) for {'penalty': 'l2', 'C': 1}\n",
      "0.640 (+/-0.067) for {'penalty': 'l1', 'C': 1}\n",
      "0.645 (+/-0.058) for {'penalty': 'l2', 'C': 10}\n",
      "0.642 (+/-0.056) for {'penalty': 'l1', 'C': 10}\n",
      "0.639 (+/-0.050) for {'penalty': 'l2', 'C': 100}\n",
      "0.639 (+/-0.050) for {'penalty': 'l1', 'C': 100}\n",
      "0.639 (+/-0.050) for {'penalty': 'l2', 'C': 1000}\n",
      "0.639 (+/-0.050) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        65\n",
      "          1       0.77      0.65      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.736 (+/-0.078) for {'penalty': 'l2', 'C': 1}\n",
      "0.746 (+/-0.077) for {'penalty': 'l1', 'C': 1}\n",
      "0.735 (+/-0.065) for {'penalty': 'l2', 'C': 10}\n",
      "0.737 (+/-0.065) for {'penalty': 'l1', 'C': 10}\n",
      "0.735 (+/-0.064) for {'penalty': 'l2', 'C': 100}\n",
      "0.736 (+/-0.064) for {'penalty': 'l1', 'C': 100}\n",
      "0.735 (+/-0.064) for {'penalty': 'l2', 'C': 1000}\n",
      "0.735 (+/-0.064) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.83      0.75        65\n",
      "          1       0.80      0.63      0.70        68\n",
      "\n",
      "avg / total       0.74      0.73      0.73       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.603 (+/-0.050) for {'penalty': 'l2', 'C': 1}\n",
      "0.603 (+/-0.054) for {'penalty': 'l1', 'C': 1}\n",
      "0.620 (+/-0.048) for {'penalty': 'l2', 'C': 10}\n",
      "0.615 (+/-0.047) for {'penalty': 'l1', 'C': 10}\n",
      "0.615 (+/-0.047) for {'penalty': 'l2', 'C': 100}\n",
      "0.615 (+/-0.047) for {'penalty': 'l1', 'C': 100}\n",
      "0.615 (+/-0.047) for {'penalty': 'l2', 'C': 1000}\n",
      "0.615 (+/-0.047) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        65\n",
      "          1       0.77      0.65      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.674 (+/-0.088) for {'penalty': 'l2', 'C': 1}\n",
      "0.684 (+/-0.098) for {'penalty': 'l1', 'C': 1}\n",
      "0.673 (+/-0.085) for {'penalty': 'l2', 'C': 10}\n",
      "0.672 (+/-0.091) for {'penalty': 'l1', 'C': 10}\n",
      "0.666 (+/-0.079) for {'penalty': 'l2', 'C': 100}\n",
      "0.666 (+/-0.079) for {'penalty': 'l1', 'C': 100}\n",
      "0.666 (+/-0.079) for {'penalty': 'l2', 'C': 1000}\n",
      "0.666 (+/-0.079) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.83      0.75        65\n",
      "          1       0.80      0.63      0.70        68\n",
      "\n",
      "avg / total       0.74      0.73      0.73       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.660 (+/-0.080) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.643 (+/-0.123) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.677 (+/-0.030) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.656 (+/-0.114) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.588 (+/-0.080) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.665 (+/-0.068) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.667 (+/-0.032) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.656 (+/-0.079) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.645 (+/-0.097) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.667 (+/-0.092) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.641 (+/-0.094) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.658 (+/-0.090) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.677 (+/-0.051) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.631 (+/-0.077) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.603 (+/-0.151) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.650 (+/-0.060) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.618 (+/-0.122) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.633 (+/-0.080) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.648 (+/-0.080) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.624 (+/-0.090) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.635 (+/-0.114) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.656 (+/-0.084) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.618 (+/-0.092) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.573 (+/-0.106) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.71      0.67        65\n",
      "          1       0.68      0.60      0.64        68\n",
      "\n",
      "avg / total       0.66      0.65      0.65       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.603 (+/-0.141) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.595 (+/-0.141) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.605 (+/-0.180) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.621 (+/-0.064) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.545 (+/-0.344) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.616 (+/-0.157) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.621 (+/-0.087) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.630 (+/-0.085) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.622 (+/-0.085) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.610 (+/-0.060) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.498 (+/-0.134) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.645 (+/-0.064) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.620 (+/-0.121) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.451 (+/-0.454) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.436 (+/-0.239) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.625 (+/-0.119) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.635 (+/-0.031) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.593 (+/-0.172) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.627 (+/-0.056) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.502 (+/-0.431) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.511 (+/-0.364) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.515 (+/-0.165) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.612 (+/-0.051) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.413 (+/-0.425) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.95      0.74        65\n",
      "          1       0.90      0.40      0.55        68\n",
      "\n",
      "avg / total       0.75      0.67      0.64       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.734 (+/-0.070) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.702 (+/-0.056) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.748 (+/-0.078) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.737 (+/-0.098) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.701 (+/-0.087) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.723 (+/-0.104) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.724 (+/-0.110) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.678 (+/-0.090) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.732 (+/-0.104) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.736 (+/-0.061) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.715 (+/-0.037) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.720 (+/-0.069) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.731 (+/-0.041) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.693 (+/-0.078) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.716 (+/-0.059) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.726 (+/-0.073) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.703 (+/-0.086) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.684 (+/-0.113) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.673 (+/-0.107) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.672 (+/-0.096) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.670 (+/-0.059) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.693 (+/-0.113) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.641 (+/-0.039) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.693 (+/-0.067) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.42      0.52        65\n",
      "          1       0.60      0.84      0.70        68\n",
      "\n",
      "avg / total       0.65      0.63      0.61       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.568 (+/-0.206) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.641 (+/-0.458) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.539 (+/-0.311) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.577 (+/-0.099) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.667 (+/-0.304) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.565 (+/-0.479) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.530 (+/-0.299) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.466 (+/-0.449) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.616 (+/-0.305) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.620 (+/-0.298) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.367 (+/-0.569) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.569 (+/-0.399) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.663 (+/-0.310) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.568 (+/-0.346) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.381 (+/-0.366) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.607 (+/-0.408) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.466 (+/-0.596) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.676 (+/-0.201) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.616 (+/-0.296) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.359 (+/-0.179) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.777 (+/-0.332) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.624 (+/-0.161) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.560 (+/-0.462) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.722 (+/-0.466) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.55      0.61        65\n",
      "          1       0.64      0.75      0.69        68\n",
      "\n",
      "avg / total       0.66      0.65      0.65       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.645 (+/-0.102) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.691 (+/-0.141) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.654 (+/-0.151) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.698 (+/-0.073) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.697 (+/-0.216) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.705 (+/-0.087) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.688 (+/-0.120) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.641 (+/-0.220) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.687 (+/-0.141) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.647 (+/-0.144) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.614 (+/-0.143) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.676 (+/-0.162) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.587 (+/-0.103) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.572 (+/-0.116) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.679 (+/-0.208) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.613 (+/-0.140) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.586 (+/-0.224) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.551 (+/-0.158) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.612 (+/-0.145) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.559 (+/-0.089) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.609 (+/-0.214) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.610 (+/-0.143) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.558 (+/-0.110) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.616 (+/-0.137) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.55      0.62        65\n",
      "          1       0.65      0.78      0.71        68\n",
      "\n",
      "avg / total       0.68      0.67      0.66       133\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 30}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.571 (+/-0.070) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.571 (+/-0.070) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.578 (+/-0.075) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.578 (+/-0.075) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.565 (+/-0.059) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.565 (+/-0.059) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.599 (+/-0.062) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.609 (+/-0.070) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.618 (+/-0.054) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.622 (+/-0.072) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.592 (+/-0.057) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.601 (+/-0.055) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.86      0.68        65\n",
      "          1       0.73      0.35      0.48        68\n",
      "\n",
      "avg / total       0.65      0.60      0.57       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.105) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.500 (+/-0.105) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.488 (+/-0.119) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.488 (+/-0.119) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.457 (+/-0.079) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.457 (+/-0.079) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.436 (+/-0.077) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.505 (+/-0.102) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.406 (+/-0.135) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.454 (+/-0.144) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.353 (+/-0.064) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.407 (+/-0.094) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.69      0.59        65\n",
      "          1       0.56      0.37      0.44        68\n",
      "\n",
      "avg / total       0.53      0.53      0.51       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.562 (+/-0.074) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.562 (+/-0.074) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.584 (+/-0.087) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.600 (+/-0.086) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.577 (+/-0.076) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.590 (+/-0.077) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.605 (+/-0.102) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.610 (+/-0.096) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.623 (+/-0.064) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.623 (+/-0.072) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.635 (+/-0.072) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.640 (+/-0.074) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.88      0.67        65\n",
      "          1       0.72      0.31      0.43        68\n",
      "\n",
      "avg / total       0.64      0.59      0.55       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.487 (+/-0.127) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.487 (+/-0.127) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.458 (+/-0.150) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.458 (+/-0.150) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.415 (+/-0.091) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.415 (+/-0.091) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.350 (+/-0.069) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.453 (+/-0.117) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.299 (+/-0.124) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.359 (+/-0.139) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.252 (+/-0.055) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.312 (+/-0.101) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.65      0.58        65\n",
      "          1       0.56      0.43      0.48        68\n",
      "\n",
      "avg / total       0.54      0.53      0.53       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 30}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.515 (+/-0.087) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.515 (+/-0.087) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.525 (+/-0.090) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.525 (+/-0.090) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.511 (+/-0.073) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.511 (+/-0.073) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.582 (+/-0.126) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.574 (+/-0.103) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.644 (+/-0.120) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.623 (+/-0.129) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.605 (+/-0.195) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.601 (+/-0.139) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.88      0.67        65\n",
      "          1       0.70      0.28      0.40        68\n",
      "\n",
      "avg / total       0.62      0.57      0.53       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.631 (+/-0.083) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        65\n",
      "          1       0.74      0.66      0.70        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.589 (+/-0.094) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        65\n",
      "          1       0.74      0.66      0.70        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.662 (+/-0.124) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        65\n",
      "          1       0.74      0.66      0.70        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.598 (+/-0.095) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        65\n",
      "          1       0.74      0.66      0.70        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.581 (+/-0.094) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.75      0.72        65\n",
      "          1       0.74      0.66      0.70        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naivebayes_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.558 (+/-0.004) for {'C': 1e-06}\n",
      "0.558 (+/-0.004) for {'C': 1e-05}\n",
      "0.571 (+/-0.037) for {'C': 0.0001}\n",
      "0.635 (+/-0.016) for {'C': 0.001}\n",
      "0.698 (+/-0.080) for {'C': 0.01}\n",
      "0.699 (+/-0.059) for {'C': 1}\n",
      "0.701 (+/-0.071) for {'C': 10}\n",
      "0.690 (+/-0.067) for {'C': 100}\n",
      "0.597 (+/-0.057) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        65\n",
      "          1       0.77      0.65      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.091 (+/-0.164) for {'C': 0.0001}\n",
      "0.424 (+/-0.092) for {'C': 0.001}\n",
      "0.612 (+/-0.089) for {'C': 0.01}\n",
      "0.645 (+/-0.053) for {'C': 1}\n",
      "0.647 (+/-0.062) for {'C': 10}\n",
      "0.659 (+/-0.115) for {'C': 100}\n",
      "0.599 (+/-0.090) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.92      0.78        65\n",
      "          1       0.89      0.59      0.71        68\n",
      "\n",
      "avg / total       0.79      0.75      0.75       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.536 (+/-0.082) for {'C': 1e-06}\n",
      "0.542 (+/-0.082) for {'C': 1e-05}\n",
      "0.581 (+/-0.089) for {'C': 0.0001}\n",
      "0.670 (+/-0.083) for {'C': 0.001}\n",
      "0.724 (+/-0.093) for {'C': 0.01}\n",
      "0.736 (+/-0.074) for {'C': 1}\n",
      "0.735 (+/-0.073) for {'C': 10}\n",
      "0.736 (+/-0.050) for {'C': 100}\n",
      "0.680 (+/-0.122) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        65\n",
      "          1       0.77      0.65      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.051 (+/-0.097) for {'C': 0.0001}\n",
      "0.308 (+/-0.110) for {'C': 0.001}\n",
      "0.539 (+/-0.079) for {'C': 0.01}\n",
      "0.615 (+/-0.047) for {'C': 1}\n",
      "0.615 (+/-0.047) for {'C': 10}\n",
      "0.564 (+/-0.139) for {'C': 100}\n",
      "0.513 (+/-0.772) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.74        65\n",
      "          1       0.77      0.65      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.600 (+/-0.778) for {'C': 0.0001}\n",
      "0.712 (+/-0.113) for {'C': 0.001}\n",
      "0.713 (+/-0.147) for {'C': 0.01}\n",
      "0.679 (+/-0.085) for {'C': 1}\n",
      "0.680 (+/-0.088) for {'C': 10}\n",
      "0.670 (+/-0.035) for {'C': 100}\n",
      "0.700 (+/-0.380) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.88      0.75        65\n",
      "          1       0.83      0.57      0.68        68\n",
      "\n",
      "avg / total       0.75      0.72      0.72       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvc_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.601 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.586 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.603 (+/-0.052) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.599 (+/-0.029) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.594 (+/-0.036) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.620 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.112) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.660 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.647 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.117) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.650 (+/-0.131) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.652 (+/-0.069) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.622 (+/-0.070) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.667 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.667 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.650 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.650 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.652 (+/-0.050) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.650 (+/-0.051) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.050) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.652 (+/-0.050) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.047) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.620 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.620 (+/-0.071) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.622 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.633 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.631 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.633 (+/-0.109) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.665 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.665 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.665 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.120) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.119) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.119) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.647 (+/-0.130) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.631 (+/-0.068) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.626 (+/-0.052) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.072) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.629 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.647 (+/-0.088) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.594 (+/-0.057) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.588 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.603 (+/-0.052) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.609 (+/-0.048) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.611 (+/-0.055) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.620 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.117) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.120) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.645 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.650 (+/-0.131) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.095) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.675 (+/-0.095) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.675 (+/-0.095) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.658 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.046) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.622 (+/-0.070) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.643 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.660 (+/-0.116) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.664 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.601 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.590 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.626 (+/-0.091) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.584 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.569 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.628 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.091) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.679 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.679 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.679 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.673 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.658 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.065) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.084) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.064) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.637 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.637 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.088) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.641 (+/-0.093) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.637 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.088) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.052) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.092) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.652 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.100) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.681 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.681 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.681 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.664 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.679 (+/-0.082) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.679 (+/-0.082) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.679 (+/-0.082) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.673 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.652 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.650 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.650 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.584 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.637 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.586 (+/-0.101) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.597 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.130) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.650 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.654 (+/-0.080) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.652 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.645 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.665 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.679 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.679 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.679 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.673 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.677 (+/-0.067) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.673 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.055) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        65\n",
      "          1       0.76      0.51      0.61        68\n",
      "\n",
      "avg / total       0.69      0.67      0.66       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.560 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.532 (+/-0.030) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.548 (+/-0.044) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.553 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.557 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.557 (+/-0.122) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.579 (+/-0.123) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.581 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.578 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.544 (+/-0.171) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.539 (+/-0.177) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.554 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.563 (+/-0.160) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.563 (+/-0.160) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.566 (+/-0.166) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.613 (+/-0.101) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.613 (+/-0.101) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.613 (+/-0.101) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.589 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.583 (+/-0.057) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.562 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.589 (+/-0.063) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.593 (+/-0.057) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.572 (+/-0.095) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.596 (+/-0.147) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.589 (+/-0.143) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.589 (+/-0.143) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.556 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.556 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.555 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.562 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.562 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.559 (+/-0.140) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.556 (+/-0.148) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.552 (+/-0.144) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.555 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.562 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.562 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.559 (+/-0.140) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.568 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.563 (+/-0.060) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.574 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.578 (+/-0.069) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.571 (+/-0.050) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.583 (+/-0.091) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.621 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.621 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.621 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.544 (+/-0.171) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.539 (+/-0.177) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.554 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.566 (+/-0.161) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.566 (+/-0.161) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.569 (+/-0.167) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.613 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.613 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.613 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.056) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.575 (+/-0.048) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.572 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.602 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.602 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.584 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.587 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.587 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.560 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.528 (+/-0.022) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.537 (+/-0.034) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.550 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.542 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.557 (+/-0.122) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.575 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.585 (+/-0.119) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.586 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.539 (+/-0.177) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.544 (+/-0.171) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.554 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.563 (+/-0.160) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.563 (+/-0.160) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.566 (+/-0.166) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.613 (+/-0.101) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.613 (+/-0.101) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.613 (+/-0.101) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.584 (+/-0.060) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.583 (+/-0.054) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.562 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.589 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.593 (+/-0.057) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.572 (+/-0.095) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.596 (+/-0.147) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.589 (+/-0.143) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.596 (+/-0.147) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.522 (+/-0.055) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.534 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.564 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.515 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.523 (+/-0.112) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.550 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.591 (+/-0.112) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.589 (+/-0.108) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.585 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.541 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.541 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.554 (+/-0.187) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.567 (+/-0.138) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.567 (+/-0.138) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.567 (+/-0.138) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.562 (+/-0.188) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.562 (+/-0.188) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.562 (+/-0.188) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.577 (+/-0.143) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.579 (+/-0.138) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.586 (+/-0.158) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.575 (+/-0.146) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.567 (+/-0.146) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.573 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.590 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.590 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.434 (+/-0.182) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.479 (+/-0.137) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.550 (+/-0.152) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.550 (+/-0.152) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.549 (+/-0.150) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.556 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.556 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.553 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.550 (+/-0.152) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.546 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.549 (+/-0.150) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.556 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.556 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.553 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.564 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.563 (+/-0.128) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.556 (+/-0.116) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.561 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.568 (+/-0.122) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.564 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.570 (+/-0.133) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.629 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.535 (+/-0.194) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.535 (+/-0.194) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.554 (+/-0.187) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.567 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.567 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.567 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.562 (+/-0.188) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.562 (+/-0.188) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.562 (+/-0.188) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.572 (+/-0.137) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.571 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.583 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.568 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.569 (+/-0.140) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.574 (+/-0.159) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.588 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.588 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.588 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.542 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.537 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.578 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.534 (+/-0.157) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.534 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.573 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.593 (+/-0.136) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.599 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.587 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.462 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.535 (+/-0.194) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.541 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.554 (+/-0.187) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.567 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.567 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.567 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.562 (+/-0.188) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.562 (+/-0.188) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.562 (+/-0.188) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.572 (+/-0.144) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.579 (+/-0.138) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.587 (+/-0.153) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.575 (+/-0.145) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.571 (+/-0.141) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.573 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.594 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.590 (+/-0.113) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.590 (+/-0.113) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.83      0.72        65\n",
      "          1       0.77      0.53      0.63        68\n",
      "\n",
      "avg / total       0.70      0.68      0.67       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.608 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.627 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.633 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.636 (+/-0.066) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.646 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.649 (+/-0.044) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.647 (+/-0.046) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.055) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.652 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.652 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.649 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.122) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.682 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.682 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.682 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.637 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.627 (+/-0.055) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.631 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.654 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.651 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.646 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.676 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.669 (+/-0.088) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.650 (+/-0.077) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.653 (+/-0.073) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.661 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.657 (+/-0.077) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.650 (+/-0.077) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.653 (+/-0.073) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.661 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.661 (+/-0.074) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.657 (+/-0.077) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.076) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.033) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.635 (+/-0.032) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.642 (+/-0.060) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.637 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.638 (+/-0.069) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.645 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.673 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.673 (+/-0.054) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.674 (+/-0.052) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.646 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.652 (+/-0.082) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.649 (+/-0.071) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.122) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.682 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.682 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.682 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.638 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.062) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.068) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.654 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.089) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.649 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.674 (+/-0.074) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.676 (+/-0.077) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.677 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.599 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.619 (+/-0.040) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.634 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.637 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.632 (+/-0.089) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.112) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.651 (+/-0.057) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.053) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.652 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.646 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.649 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.658 (+/-0.122) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.682 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.682 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.682 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.640 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.636 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.631 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.650 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.646 (+/-0.103) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.675 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.669 (+/-0.088) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.667 (+/-0.084) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.590 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.612 (+/-0.094) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.635 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.619 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.621 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.649 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.670 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.664 (+/-0.064) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.075) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.676 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.676 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.676 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.641 (+/-0.086) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.650 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.658 (+/-0.057) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.685 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.678 (+/-0.074) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.685 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.673 (+/-0.082) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.662 (+/-0.107) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.094) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.643 (+/-0.093) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.093) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.647 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.654 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.654 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.649 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.649 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.647 (+/-0.090) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.654 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.654 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.651 (+/-0.092) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.071) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.617 (+/-0.056) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.621 (+/-0.068) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.630 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.097) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.654 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.657 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.682 (+/-0.070) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.675 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.675 (+/-0.063) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.086) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.676 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.676 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.676 (+/-0.079) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.630 (+/-0.101) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.088) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.650 (+/-0.065) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.064) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.674 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.678 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.677 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.677 (+/-0.075) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.676 (+/-0.076) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.577 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.616 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.631 (+/-0.089) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.623 (+/-0.120) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.626 (+/-0.085) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.151) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.674 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.661 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.639 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.656 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.086) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.656 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.661 (+/-0.075) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.676 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.676 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.676 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.638 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.644 (+/-0.089) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.659 (+/-0.056) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.680 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.682 (+/-0.085) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.687 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.080) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.673 (+/-0.082) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.674 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.83      0.69        65\n",
      "          1       0.74      0.46      0.56        68\n",
      "\n",
      "avg / total       0.67      0.64      0.63       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.577 (+/-0.080) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.534 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.526 (+/-0.072) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.560 (+/-0.074) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.539 (+/-0.074) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.543 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.551 (+/-0.122) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.534 (+/-0.119) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.538 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.487 (+/-0.217) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.487 (+/-0.217) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.504 (+/-0.176) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.517 (+/-0.166) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.132) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.581 (+/-0.132) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.581 (+/-0.132) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.564 (+/-0.047) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.543 (+/-0.063) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.547 (+/-0.069) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.585 (+/-0.060) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.560 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.551 (+/-0.141) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.551 (+/-0.141) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.551 (+/-0.141) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.504 (+/-0.253) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.509 (+/-0.257) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.568 (+/-0.098) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.564 (+/-0.126) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.577 (+/-0.085) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.560 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.551 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.577 (+/-0.108) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.620 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.620 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.620 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.487 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.487 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.504 (+/-0.176) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.534 (+/-0.180) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.534 (+/-0.180) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.530 (+/-0.169) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.581 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.581 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.568 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.577 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.569 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.598 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.598 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.590 (+/-0.124) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.560 (+/-0.145) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.556 (+/-0.137) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.560 (+/-0.145) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.577 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.530 (+/-0.064) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.526 (+/-0.072) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.568 (+/-0.066) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.560 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.534 (+/-0.127) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.534 (+/-0.119) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.538 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.543 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.487 (+/-0.217) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.487 (+/-0.217) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.504 (+/-0.176) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.521 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.521 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.517 (+/-0.166) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.581 (+/-0.132) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.581 (+/-0.132) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.581 (+/-0.132) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.551 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.551 (+/-0.054) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.547 (+/-0.069) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.585 (+/-0.060) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.585 (+/-0.060) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.560 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.564 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.564 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.551 (+/-0.141) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.552 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.543 (+/-0.150) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.573 (+/-0.180) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.543 (+/-0.188) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.560 (+/-0.121) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.560 (+/-0.215) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.573 (+/-0.146) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.573 (+/-0.146) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.568 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.461 (+/-0.226) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.457 (+/-0.231) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.483 (+/-0.171) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.483 (+/-0.171) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.171) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.487 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.487 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.487 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.500 (+/-0.173) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.509 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.534 (+/-0.208) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.526 (+/-0.221) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.521 (+/-0.219) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.539 (+/-0.262) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.560 (+/-0.185) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.569 (+/-0.175) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.560 (+/-0.185) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.334 (+/-0.238) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.372 (+/-0.168) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.509 (+/-0.254) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.509 (+/-0.254) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.509 (+/-0.254) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.513 (+/-0.258) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.517 (+/-0.237) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.517 (+/-0.187) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.513 (+/-0.181) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.526 (+/-0.191) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.517 (+/-0.198) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.526 (+/-0.196) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.534 (+/-0.199) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.611 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.611 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.611 (+/-0.138) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.457 (+/-0.231) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.461 (+/-0.226) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.224) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.483 (+/-0.171) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.483 (+/-0.171) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.171) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.487 (+/-0.224) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.487 (+/-0.224) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.487 (+/-0.224) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.513 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.526 (+/-0.190) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.535 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.534 (+/-0.249) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.534 (+/-0.243) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.552 (+/-0.255) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.560 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.560 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.560 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.522 (+/-0.117) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.534 (+/-0.137) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.569 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.543 (+/-0.233) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.513 (+/-0.228) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.556 (+/-0.218) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.568 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.577 (+/-0.177) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.564 (+/-0.132) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.346 (+/-0.090) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.457 (+/-0.231) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.457 (+/-0.231) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.483 (+/-0.171) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.483 (+/-0.171) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.483 (+/-0.171) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.487 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.487 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.487 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.509 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.509 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.534 (+/-0.208) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.521 (+/-0.228) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.526 (+/-0.239) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.539 (+/-0.262) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.560 (+/-0.185) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.569 (+/-0.175) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.560 (+/-0.185) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        65\n",
      "          1       0.76      0.51      0.61        68\n",
      "\n",
      "avg / total       0.69      0.67      0.66       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.556 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.546 (+/-0.102) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.566 (+/-0.099) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.546 (+/-0.036) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.557 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.580 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.628 (+/-0.129) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.633 (+/-0.147) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.629 (+/-0.176) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.176) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.618 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.617 (+/-0.168) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.617 (+/-0.168) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.180) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.657 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.657 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.657 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.622 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.620 (+/-0.073) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.584 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.607 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.602 (+/-0.130) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.590 (+/-0.158) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.642 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.642 (+/-0.163) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.140) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.641 (+/-0.103) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.646 (+/-0.096) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.661 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.646 (+/-0.096) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.641 (+/-0.103) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.661 (+/-0.147) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.580 (+/-0.105) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.579 (+/-0.119) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.579 (+/-0.121) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.603 (+/-0.166) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.604 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.600 (+/-0.192) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.633 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.633 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.633 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.622 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.622 (+/-0.174) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.618 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.606 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.617 (+/-0.177) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.657 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.657 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.657 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.596 (+/-0.111) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.593 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.586 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.606 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.103) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.592 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.619 (+/-0.134) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.619 (+/-0.134) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.608 (+/-0.102) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.543 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.536 (+/-0.112) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.554 (+/-0.091) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.536 (+/-0.018) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.556 (+/-0.029) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.580 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.642 (+/-0.139) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.625 (+/-0.130) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.622 (+/-0.174) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.622 (+/-0.174) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.618 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.617 (+/-0.168) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.617 (+/-0.168) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.627 (+/-0.180) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.657 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.657 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.657 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.624 (+/-0.125) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.619 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.584 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.605 (+/-0.131) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.602 (+/-0.130) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.590 (+/-0.158) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.635 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.642 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.635 (+/-0.163) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.539 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.541 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.573 (+/-0.112) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.542 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.531 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.579 (+/-0.181) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.615 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.622 (+/-0.117) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.622 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.106) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.110) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.706 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.706 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.706 (+/-0.164) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.687 (+/-0.148) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.687 (+/-0.148) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.687 (+/-0.148) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.676 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.675 (+/-0.165) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.653 (+/-0.123) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.655 (+/-0.125) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.643 (+/-0.101) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.636 (+/-0.147) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.640 (+/-0.150) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.640 (+/-0.150) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.264) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.699 (+/-0.167) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.626 (+/-0.150) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.185) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.185) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.643 (+/-0.188) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.629 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.626 (+/-0.150) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.185) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.185) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.643 (+/-0.188) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.648 (+/-0.116) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.625 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.626 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.627 (+/-0.181) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.645 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.161) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.638 (+/-0.187) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.658 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.658 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.658 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.106) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.110) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.706 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.706 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.706 (+/-0.164) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.687 (+/-0.148) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.687 (+/-0.148) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.687 (+/-0.148) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.128) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.651 (+/-0.157) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.670 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.633 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.629 (+/-0.121) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.631 (+/-0.143) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.634 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.634 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.634 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.540 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.548 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.599 (+/-0.146) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.540 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.545 (+/-0.094) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.594 (+/-0.181) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.630 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.626 (+/-0.109) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.615 (+/-0.108) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.704 (+/-0.165) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.671 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.671 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.667 (+/-0.110) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.706 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.706 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.706 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.687 (+/-0.148) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.687 (+/-0.148) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.687 (+/-0.148) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.675 (+/-0.098) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.675 (+/-0.102) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.668 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.652 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.643 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.637 (+/-0.099) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.640 (+/-0.150) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.640 (+/-0.150) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.636 (+/-0.147) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.83      0.72        65\n",
      "          1       0.77      0.53      0.63        68\n",
      "\n",
      "avg / total       0.70      0.68      0.67       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decsiontree_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.645 (+/-0.054) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.643 (+/-0.073) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.654 (+/-0.065) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.654 (+/-0.025) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.648 (+/-0.057) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.673 (+/-0.082) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.681 (+/-0.041) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.664 (+/-0.074) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.667 (+/-0.081) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.664 (+/-0.070) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.671 (+/-0.095) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.664 (+/-0.100) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.677 (+/-0.096) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.681 (+/-0.096) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.675 (+/-0.099) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.686 (+/-0.111) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.662 (+/-0.097) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.682 (+/-0.092) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.656 (+/-0.097) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.679 (+/-0.084) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.682 (+/-0.105) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.682 (+/-0.135) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.696 (+/-0.099) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.682 (+/-0.099) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.85      0.73        65\n",
      "          1       0.79      0.54      0.64        68\n",
      "\n",
      "avg / total       0.72      0.69      0.69       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.487 (+/-0.079) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.481 (+/-0.104) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.508 (+/-0.145) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.504 (+/-0.074) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.437 (+/-0.128) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.473 (+/-0.063) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.460 (+/-0.039) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.449 (+/-0.161) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.544 (+/-0.129) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.576 (+/-0.049) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.590 (+/-0.112) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.569 (+/-0.136) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.606 (+/-0.119) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.558 (+/-0.102) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.560 (+/-0.153) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.544 (+/-0.115) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.554 (+/-0.138) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.580 (+/-0.068) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.605 (+/-0.078) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.593 (+/-0.132) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.562 (+/-0.121) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.598 (+/-0.166) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.566 (+/-0.147) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.577 (+/-0.107) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.85      0.72        65\n",
      "          1       0.78      0.51      0.62        68\n",
      "\n",
      "avg / total       0.70      0.68      0.67       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.663 (+/-0.092) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.694 (+/-0.105) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.696 (+/-0.082) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.690 (+/-0.072) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.674 (+/-0.108) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.711 (+/-0.068) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.709 (+/-0.100) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.705 (+/-0.069) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.709 (+/-0.050) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.691 (+/-0.102) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.712 (+/-0.081) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.715 (+/-0.071) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.704 (+/-0.030) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.713 (+/-0.062) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.716 (+/-0.081) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.707 (+/-0.068) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.697 (+/-0.076) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.713 (+/-0.066) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.707 (+/-0.053) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.715 (+/-0.063) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.700 (+/-0.032) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.728 (+/-0.070) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.719 (+/-0.075) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.724 (+/-0.047) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.86      0.72        65\n",
      "          1       0.79      0.49      0.60        68\n",
      "\n",
      "avg / total       0.70      0.67      0.66       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.393 (+/-0.076) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.411 (+/-0.111) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.410 (+/-0.068) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.436 (+/-0.138) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.363 (+/-0.115) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.316 (+/-0.090) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.312 (+/-0.083) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.334 (+/-0.108) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.483 (+/-0.125) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.466 (+/-0.120) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.492 (+/-0.124) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.513 (+/-0.123) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.483 (+/-0.100) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.440 (+/-0.089) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.453 (+/-0.037) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.466 (+/-0.103) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.487 (+/-0.092) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.517 (+/-0.098) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.500 (+/-0.144) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.487 (+/-0.072) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.492 (+/-0.110) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.513 (+/-0.125) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.492 (+/-0.115) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.500 (+/-0.117) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.89      0.74        65\n",
      "          1       0.83      0.50      0.62        68\n",
      "\n",
      "avg / total       0.73      0.69      0.68       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.666 (+/-0.133) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.679 (+/-0.112) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.707 (+/-0.098) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.675 (+/-0.078) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.754 (+/-0.157) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.785 (+/-0.123) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.767 (+/-0.216) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.747 (+/-0.201) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.660 (+/-0.153) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.716 (+/-0.122) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.690 (+/-0.170) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.694 (+/-0.119) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.719 (+/-0.173) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.732 (+/-0.142) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.745 (+/-0.161) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.718 (+/-0.229) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.663 (+/-0.132) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.682 (+/-0.250) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.675 (+/-0.165) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.697 (+/-0.149) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.707 (+/-0.116) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.732 (+/-0.166) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.750 (+/-0.162) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.719 (+/-0.226) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.91      0.70        65\n",
      "          1       0.80      0.35      0.49        68\n",
      "\n",
      "avg / total       0.69      0.62      0.59       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomforest_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_drop_du_dropped_2 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.832 (+/-0.036) for {'penalty': 'l2', 'C': 1}\n",
      "0.837 (+/-0.034) for {'penalty': 'l1', 'C': 1}\n",
      "0.837 (+/-0.026) for {'penalty': 'l2', 'C': 10}\n",
      "0.836 (+/-0.029) for {'penalty': 'l1', 'C': 10}\n",
      "0.837 (+/-0.026) for {'penalty': 'l2', 'C': 100}\n",
      "0.837 (+/-0.026) for {'penalty': 'l1', 'C': 100}\n",
      "0.837 (+/-0.026) for {'penalty': 'l2', 'C': 1000}\n",
      "0.837 (+/-0.026) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       103\n",
      "          1       0.80      0.27      0.40        30\n",
      "\n",
      "avg / total       0.82      0.82      0.78       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.303 (+/-0.308) for {'penalty': 'l2', 'C': 1}\n",
      "0.359 (+/-0.224) for {'penalty': 'l1', 'C': 1}\n",
      "0.382 (+/-0.154) for {'penalty': 'l2', 'C': 10}\n",
      "0.368 (+/-0.186) for {'penalty': 'l1', 'C': 10}\n",
      "0.382 (+/-0.154) for {'penalty': 'l2', 'C': 100}\n",
      "0.382 (+/-0.154) for {'penalty': 'l1', 'C': 100}\n",
      "0.382 (+/-0.154) for {'penalty': 'l2', 'C': 1000}\n",
      "0.382 (+/-0.154) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       103\n",
      "          1       0.77      0.33      0.47        30\n",
      "\n",
      "avg / total       0.82      0.83      0.80       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.753 (+/-0.028) for {'penalty': 'l2', 'C': 1}\n",
      "0.755 (+/-0.032) for {'penalty': 'l1', 'C': 1}\n",
      "0.752 (+/-0.037) for {'penalty': 'l2', 'C': 10}\n",
      "0.751 (+/-0.037) for {'penalty': 'l1', 'C': 10}\n",
      "0.751 (+/-0.040) for {'penalty': 'l2', 'C': 100}\n",
      "0.751 (+/-0.039) for {'penalty': 'l1', 'C': 100}\n",
      "0.751 (+/-0.040) for {'penalty': 'l2', 'C': 1000}\n",
      "0.751 (+/-0.040) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       103\n",
      "          1       0.80      0.27      0.40        30\n",
      "\n",
      "avg / total       0.82      0.82      0.78       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.230 (+/-0.246) for {'penalty': 'l2', 'C': 1}\n",
      "0.275 (+/-0.202) for {'penalty': 'l1', 'C': 1}\n",
      "0.297 (+/-0.153) for {'penalty': 'l2', 'C': 10}\n",
      "0.286 (+/-0.179) for {'penalty': 'l1', 'C': 10}\n",
      "0.297 (+/-0.153) for {'penalty': 'l2', 'C': 100}\n",
      "0.297 (+/-0.153) for {'penalty': 'l1', 'C': 100}\n",
      "0.297 (+/-0.153) for {'penalty': 'l2', 'C': 1000}\n",
      "0.297 (+/-0.153) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       103\n",
      "          1       0.77      0.33      0.47        30\n",
      "\n",
      "avg / total       0.82      0.83      0.80       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.480 (+/-0.524) for {'penalty': 'l2', 'C': 1}\n",
      "0.540 (+/-0.196) for {'penalty': 'l1', 'C': 1}\n",
      "0.544 (+/-0.113) for {'penalty': 'l2', 'C': 10}\n",
      "0.529 (+/-0.145) for {'penalty': 'l1', 'C': 10}\n",
      "0.544 (+/-0.113) for {'penalty': 'l2', 'C': 100}\n",
      "0.544 (+/-0.113) for {'penalty': 'l1', 'C': 100}\n",
      "0.544 (+/-0.113) for {'penalty': 'l2', 'C': 1000}\n",
      "0.544 (+/-0.113) for {'penalty': 'l1', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       103\n",
      "          1       0.77      0.33      0.47        30\n",
      "\n",
      "avg / total       0.82      0.83      0.80       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.830 (+/-0.044) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.798 (+/-0.095) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.820 (+/-0.003) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.832 (+/-0.016) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.798 (+/-0.099) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.826 (+/-0.036) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.828 (+/-0.043) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.824 (+/-0.024) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.820 (+/-0.031) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.817 (+/-0.020) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.826 (+/-0.024) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.826 (+/-0.027) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.834 (+/-0.065) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.773 (+/-0.229) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.769 (+/-0.187) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.807 (+/-0.089) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.750 (+/-0.234) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.784 (+/-0.106) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.815 (+/-0.066) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.809 (+/-0.096) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.788 (+/-0.059) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.750 (+/-0.117) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.805 (+/-0.059) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.790 (+/-0.167) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90       103\n",
      "          1       0.72      0.43      0.54        30\n",
      "\n",
      "avg / total       0.82      0.83      0.82       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.142 (+/-0.315) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.233 (+/-0.374) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.320 (+/-0.276) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.250 (+/-0.413) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.412 (+/-0.141) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.208 (+/-0.395) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.112 (+/-0.204) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.272 (+/-0.407) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.345 (+/-0.309) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.276 (+/-0.327) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.209 (+/-0.316) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.167 (+/-0.319) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.427 (+/-0.070) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.380 (+/-0.051) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.197 (+/-0.370) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.402 (+/-0.163) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.361 (+/-0.181) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.322 (+/-0.126) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.340 (+/-0.284) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.355 (+/-0.213) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.279 (+/-0.455) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.424 (+/-0.075) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.333 (+/-0.254) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.226 (+/-0.333) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.99      0.90       103\n",
      "          1       0.89      0.27      0.41        30\n",
      "\n",
      "avg / total       0.84      0.83      0.79       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.768 (+/-0.107) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.754 (+/-0.042) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.746 (+/-0.023) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.762 (+/-0.109) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.723 (+/-0.055) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.736 (+/-0.030) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.773 (+/-0.114) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.745 (+/-0.064) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.753 (+/-0.038) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.749 (+/-0.067) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.735 (+/-0.059) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.731 (+/-0.038) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.709 (+/-0.051) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.719 (+/-0.087) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.734 (+/-0.067) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.745 (+/-0.075) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.752 (+/-0.039) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.703 (+/-0.072) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.728 (+/-0.052) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.711 (+/-0.055) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.708 (+/-0.159) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.710 (+/-0.092) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.696 (+/-0.099) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.708 (+/-0.074) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       103\n",
      "          1       1.00      0.07      0.12        30\n",
      "\n",
      "avg / total       0.83      0.79      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.144 (+/-0.355) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.133 (+/-0.249) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.229 (+/-0.306) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.177 (+/-0.258) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.155 (+/-0.237) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.188 (+/-0.376) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.066 (+/-0.177) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.221 (+/-0.274) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.110 (+/-0.234) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.187 (+/-0.341) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.244 (+/-0.413) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.218 (+/-0.361) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.470 (+/-0.343) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.405 (+/-0.446) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.343 (+/-0.600) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.494 (+/-0.352) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.358 (+/-0.614) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.288 (+/-0.406) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.286 (+/-0.333) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.195 (+/-0.360) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.315 (+/-0.497) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.387 (+/-0.540) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.339 (+/-0.468) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.286 (+/-0.366) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       103\n",
      "          1       1.00      0.13      0.24        30\n",
      "\n",
      "avg / total       0.84      0.80      0.74       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.372 (+/-0.397) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.526 (+/-0.664) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.459 (+/-0.361) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.500 (+/-0.636) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.412 (+/-0.391) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.356 (+/-0.080) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.517 (+/-0.655) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01}\n",
      "0.193 (+/-0.344) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01}\n",
      "0.242 (+/-0.409) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01}\n",
      "0.608 (+/-0.756) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.338 (+/-0.357) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.336 (+/-0.495) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01}\n",
      "0.454 (+/-0.237) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001}\n",
      "0.445 (+/-0.193) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001}\n",
      "0.423 (+/-0.217) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001}\n",
      "0.437 (+/-0.246) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.309 (+/-0.516) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.492 (+/-0.663) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001}\n",
      "0.368 (+/-0.277) for {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.400 (+/-0.106) for {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.257 (+/-0.274) for {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001}\n",
      "0.427 (+/-0.305) for {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.311 (+/-0.334) for {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "0.474 (+/-0.285) for {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sgd_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.766 (+/-0.039) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.766 (+/-0.039) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.790 (+/-0.036) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.790 (+/-0.036) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.811 (+/-0.015) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.811 (+/-0.015) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.828 (+/-0.006) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.826 (+/-0.008) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.828 (+/-0.006) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.828 (+/-0.006) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.828 (+/-0.006) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.828 (+/-0.006) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       103\n",
      "          1       1.00      0.03      0.06        30\n",
      "\n",
      "avg / total       0.83      0.78      0.69       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.202 (+/-0.144) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.202 (+/-0.144) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.118 (+/-0.174) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.118 (+/-0.174) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.071 (+/-0.131) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.071 (+/-0.131) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.039 (+/-0.096) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       103\n",
      "          1       0.40      0.33      0.36        30\n",
      "\n",
      "avg / total       0.72      0.74      0.73       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.532 (+/-0.064) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.532 (+/-0.064) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.594 (+/-0.105) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.592 (+/-0.107) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.576 (+/-0.112) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.586 (+/-0.118) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.632 (+/-0.084) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.616 (+/-0.076) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.645 (+/-0.042) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.648 (+/-0.040) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.687 (+/-0.096) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.687 (+/-0.090) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.176 (+/-0.130) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.176 (+/-0.130) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.088 (+/-0.134) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.088 (+/-0.134) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.044 (+/-0.083) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.044 (+/-0.083) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.022 (+/-0.053) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       103\n",
      "          1       0.40      0.33      0.36        30\n",
      "\n",
      "avg / total       0.72      0.74      0.73       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.240 (+/-0.157) for {'weights': 'uniform', 'n_neighbors': 1}\n",
      "0.240 (+/-0.157) for {'weights': 'distance', 'n_neighbors': 1}\n",
      "0.183 (+/-0.258) for {'weights': 'uniform', 'n_neighbors': 3}\n",
      "0.183 (+/-0.258) for {'weights': 'distance', 'n_neighbors': 3}\n",
      "0.196 (+/-0.335) for {'weights': 'uniform', 'n_neighbors': 5}\n",
      "0.196 (+/-0.335) for {'weights': 'distance', 'n_neighbors': 5}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 10}\n",
      "0.200 (+/-0.490) for {'weights': 'distance', 'n_neighbors': 10}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 30}\n",
      "0.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 50}\n",
      "0.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       103\n",
      "          1       0.40      0.33      0.36        30\n",
      "\n",
      "avg / total       0.72      0.74      0.73       133\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "knn_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.754 (+/-0.065) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.374 (+/-0.210) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.673 (+/-0.096) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.438 (+/-0.287) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.330 (+/-0.166) for {'priors': None}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naivebayes_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.828 (+/-0.006) for {'C': 1e-06}\n",
      "0.828 (+/-0.006) for {'C': 1e-05}\n",
      "0.828 (+/-0.006) for {'C': 0.0001}\n",
      "0.828 (+/-0.006) for {'C': 0.001}\n",
      "0.822 (+/-0.008) for {'C': 0.01}\n",
      "0.830 (+/-0.033) for {'C': 1}\n",
      "0.832 (+/-0.028) for {'C': 10}\n",
      "0.826 (+/-0.040) for {'C': 100}\n",
      "0.677 (+/-0.363) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.99      0.89       103\n",
      "          1       0.88      0.23      0.37        30\n",
      "\n",
      "avg / total       0.83      0.82      0.78       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.000 (+/-0.000) for {'C': 0.0001}\n",
      "0.000 (+/-0.000) for {'C': 0.001}\n",
      "0.019 (+/-0.076) for {'C': 0.01}\n",
      "0.303 (+/-0.271) for {'C': 1}\n",
      "0.327 (+/-0.282) for {'C': 10}\n",
      "0.351 (+/-0.163) for {'C': 100}\n",
      "0.375 (+/-0.210) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       103\n",
      "          1       1.00      0.03      0.06        30\n",
      "\n",
      "avg / total       0.83      0.78      0.69       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.521 (+/-0.098) for {'C': 1e-06}\n",
      "0.524 (+/-0.098) for {'C': 1e-05}\n",
      "0.533 (+/-0.092) for {'C': 0.0001}\n",
      "0.624 (+/-0.056) for {'C': 0.001}\n",
      "0.741 (+/-0.024) for {'C': 0.01}\n",
      "0.760 (+/-0.037) for {'C': 1}\n",
      "0.760 (+/-0.034) for {'C': 10}\n",
      "0.762 (+/-0.054) for {'C': 100}\n",
      "0.698 (+/-0.086) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.99      0.89       103\n",
      "          1       0.86      0.20      0.32        30\n",
      "\n",
      "avg / total       0.82      0.81      0.76       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.000 (+/-0.000) for {'C': 0.0001}\n",
      "0.000 (+/-0.000) for {'C': 0.001}\n",
      "0.011 (+/-0.044) for {'C': 0.01}\n",
      "0.231 (+/-0.239) for {'C': 1}\n",
      "0.242 (+/-0.261) for {'C': 10}\n",
      "0.241 (+/-0.192) for {'C': 100}\n",
      "0.197 (+/-0.248) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.99      0.89       103\n",
      "          1       0.88      0.23      0.37        30\n",
      "\n",
      "avg / total       0.83      0.82      0.78       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-06}\n",
      "0.000 (+/-0.000) for {'C': 1e-05}\n",
      "0.000 (+/-0.000) for {'C': 0.0001}\n",
      "0.000 (+/-0.000) for {'C': 0.001}\n",
      "0.066 (+/-0.266) for {'C': 0.01}\n",
      "0.478 (+/-0.215) for {'C': 1}\n",
      "0.492 (+/-0.195) for {'C': 10}\n",
      "0.551 (+/-0.219) for {'C': 100}\n",
      "0.442 (+/-0.266) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89       103\n",
      "          1       0.75      0.20      0.32        30\n",
      "\n",
      "avg / total       0.79      0.80      0.76       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvc_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.752 (+/-0.041) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.775 (+/-0.042) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.794 (+/-0.048) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.805 (+/-0.041) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.809 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.813 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.820 (+/-0.078) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.822 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.839 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.839 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.839 (+/-0.035) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.824 (+/-0.053) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.824 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.834 (+/-0.054) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.828 (+/-0.050) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.836 (+/-0.030) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.836 (+/-0.030) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.836 (+/-0.030) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.813 (+/-0.045) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.796 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.807 (+/-0.057) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.809 (+/-0.056) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.811 (+/-0.062) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.819 (+/-0.052) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.820 (+/-0.078) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.820 (+/-0.078) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.809 (+/-0.046) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.809 (+/-0.046) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.809 (+/-0.046) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.836 (+/-0.021) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.836 (+/-0.021) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.836 (+/-0.021) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.832 (+/-0.023) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.832 (+/-0.023) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.832 (+/-0.023) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.832 (+/-0.023) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.834 (+/-0.025) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.798 (+/-0.019) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.803 (+/-0.013) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.807 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.815 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.815 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.820 (+/-0.041) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.819 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.819 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.819 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.839 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.839 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.839 (+/-0.035) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.045) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.820 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.822 (+/-0.044) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.832 (+/-0.047) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.048) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.836 (+/-0.030) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.836 (+/-0.030) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.836 (+/-0.030) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.817 (+/-0.037) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.798 (+/-0.023) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.798 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.813 (+/-0.066) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.817 (+/-0.057) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.815 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.820 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.820 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.820 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.735 (+/-0.048) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.777 (+/-0.046) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.790 (+/-0.050) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.796 (+/-0.040) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.803 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.813 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.822 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.822 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.839 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.839 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.839 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.822 (+/-0.045) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.824 (+/-0.053) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.822 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.834 (+/-0.054) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.834 (+/-0.054) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.830 (+/-0.048) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.836 (+/-0.030) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.836 (+/-0.030) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.836 (+/-0.030) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.820 (+/-0.044) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.798 (+/-0.031) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.802 (+/-0.058) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.811 (+/-0.064) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.809 (+/-0.056) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.813 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.820 (+/-0.078) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.820 (+/-0.078) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.822 (+/-0.071) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.781 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.788 (+/-0.071) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.792 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.790 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.788 (+/-0.076) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.805 (+/-0.079) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.807 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.807 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.807 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.805 (+/-0.031) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.805 (+/-0.031) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.819 (+/-0.043) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.031) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.031) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.822 (+/-0.049) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.824 (+/-0.070) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.824 (+/-0.070) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.824 (+/-0.070) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.802 (+/-0.050) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.800 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.805 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.819 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.819 (+/-0.051) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.063) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.819 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.817 (+/-0.061) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.819 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.813 (+/-0.035) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.837 (+/-0.020) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.790 (+/-0.050) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.802 (+/-0.029) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.809 (+/-0.046) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.027) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.027) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.817 (+/-0.053) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.813 (+/-0.067) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.805 (+/-0.031) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.805 (+/-0.031) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.819 (+/-0.043) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.031) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.031) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.822 (+/-0.049) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.824 (+/-0.070) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.824 (+/-0.070) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.824 (+/-0.070) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.807 (+/-0.023) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.803 (+/-0.030) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.803 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.811 (+/-0.056) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.811 (+/-0.056) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.817 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.817 (+/-0.061) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.819 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.819 (+/-0.059) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.766 (+/-0.034) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.783 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.788 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.794 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.794 (+/-0.074) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.805 (+/-0.079) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.809 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.809 (+/-0.077) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.807 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.037) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.037) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.815 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.815 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.039) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.805 (+/-0.031) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.805 (+/-0.031) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.819 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.813 (+/-0.031) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.813 (+/-0.031) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.822 (+/-0.049) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.824 (+/-0.070) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.824 (+/-0.070) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.824 (+/-0.070) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.798 (+/-0.053) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.800 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.805 (+/-0.059) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.819 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.819 (+/-0.051) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.815 (+/-0.063) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.817 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.817 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.817 (+/-0.061) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.93       103\n",
      "          1       0.85      0.57      0.68        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.281 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.316 (+/-0.170) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.311 (+/-0.219) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.368 (+/-0.229) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.382 (+/-0.215) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.359 (+/-0.265) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.335 (+/-0.210) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.336 (+/-0.207) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.336 (+/-0.207) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.426 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.426 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.426 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.371 (+/-0.183) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.381 (+/-0.211) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.240) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.397 (+/-0.260) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.353 (+/-0.271) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.341 (+/-0.279) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.181) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.181) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.181) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.375 (+/-0.201) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.199) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.298 (+/-0.219) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.396 (+/-0.264) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.396 (+/-0.264) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.354 (+/-0.272) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.336 (+/-0.207) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.335 (+/-0.210) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.335 (+/-0.210) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.157 (+/-0.388) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.157 (+/-0.388) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.157 (+/-0.388) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.380 (+/-0.097) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.380 (+/-0.097) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.380 (+/-0.097) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.375 (+/-0.101) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.375 (+/-0.101) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.375 (+/-0.101) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.373 (+/-0.104) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.375 (+/-0.101) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.375 (+/-0.101) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.378 (+/-0.100) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.338 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.331 (+/-0.170) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.340 (+/-0.236) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.343 (+/-0.265) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.363 (+/-0.263) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.366 (+/-0.263) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.309 (+/-0.210) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.309 (+/-0.210) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.309 (+/-0.210) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.426 (+/-0.159) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.426 (+/-0.159) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.426 (+/-0.159) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.383 (+/-0.145) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.364 (+/-0.170) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.364 (+/-0.225) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.410 (+/-0.229) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.366 (+/-0.250) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.341 (+/-0.279) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.181) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.181) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.181) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.333 (+/-0.143) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.150) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.275 (+/-0.232) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.366 (+/-0.267) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.377 (+/-0.245) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.359 (+/-0.265) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.336 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.336 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.335 (+/-0.210) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.304 (+/-0.073) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.299 (+/-0.120) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.288 (+/-0.236) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.366 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.368 (+/-0.228) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.359 (+/-0.265) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.335 (+/-0.210) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.335 (+/-0.210) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.335 (+/-0.210) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.430 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.426 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.426 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.426 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.371 (+/-0.183) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.371 (+/-0.188) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.364 (+/-0.225) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.397 (+/-0.260) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.397 (+/-0.260) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.341 (+/-0.279) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.358 (+/-0.181) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.358 (+/-0.181) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.358 (+/-0.181) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.363 (+/-0.182) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.293 (+/-0.164) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.306 (+/-0.223) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.366 (+/-0.260) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.380 (+/-0.242) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.347 (+/-0.283) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.336 (+/-0.207) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.336 (+/-0.207) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.335 (+/-0.210) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.285 (+/-0.116) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.327 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.342 (+/-0.229) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.343 (+/-0.200) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.341 (+/-0.190) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.330 (+/-0.274) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.323 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.323 (+/-0.224) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.321 (+/-0.227) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.307 (+/-0.319) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.307 (+/-0.319) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.397 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.303 (+/-0.312) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.303 (+/-0.312) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.411 (+/-0.093) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.424 (+/-0.162) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.424 (+/-0.162) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.424 (+/-0.162) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.395 (+/-0.169) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.351 (+/-0.187) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.311 (+/-0.322) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.365 (+/-0.249) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.365 (+/-0.249) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.363 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.292 (+/-0.295) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.293 (+/-0.293) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.292 (+/-0.295) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.161 (+/-0.397) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.383 (+/-0.095) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.326 (+/-0.206) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.309 (+/-0.229) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.350 (+/-0.218) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.338 (+/-0.253) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.350 (+/-0.233) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.364 (+/-0.230) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.303 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.303 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.303 (+/-0.217) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.307 (+/-0.319) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.307 (+/-0.319) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.397 (+/-0.100) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.303 (+/-0.312) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.303 (+/-0.312) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.411 (+/-0.093) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.424 (+/-0.162) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.424 (+/-0.162) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.424 (+/-0.162) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.386 (+/-0.149) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.338 (+/-0.135) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.316 (+/-0.296) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.358 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.358 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.393 (+/-0.226) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.293 (+/-0.293) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.293 (+/-0.293) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.292 (+/-0.295) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.331 (+/-0.129) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.339 (+/-0.217) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.342 (+/-0.229) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.332 (+/-0.222) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.316 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.343 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.321 (+/-0.227) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.323 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.321 (+/-0.227) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.235 (+/-0.387) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.307 (+/-0.319) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.307 (+/-0.319) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.397 (+/-0.100) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.303 (+/-0.312) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.303 (+/-0.312) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.411 (+/-0.093) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.424 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.424 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.424 (+/-0.162) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.388 (+/-0.160) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.351 (+/-0.187) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.311 (+/-0.322) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.365 (+/-0.249) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.365 (+/-0.249) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.376 (+/-0.235) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.292 (+/-0.295) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.292 (+/-0.295) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.293 (+/-0.293) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.572 (+/-0.059) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.618 (+/-0.067) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.640 (+/-0.081) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.664 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.667 (+/-0.144) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.697 (+/-0.120) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.697 (+/-0.105) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.694 (+/-0.081) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.694 (+/-0.081) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.694 (+/-0.081) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.643 (+/-0.107) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.594 (+/-0.085) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.625 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.149) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.149) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.654 (+/-0.103) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.113) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.541 (+/-0.176) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.580 (+/-0.114) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.616 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.629 (+/-0.160) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.644 (+/-0.166) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.662 (+/-0.074) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.700 (+/-0.119) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.686 (+/-0.111) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.684 (+/-0.136) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.715 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.715 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.715 (+/-0.143) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.717 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.713 (+/-0.126) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.126) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.126) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.714 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.714 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.714 (+/-0.128) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.713 (+/-0.129) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.713 (+/-0.129) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.713 (+/-0.129) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.119) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.726 (+/-0.078) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.722 (+/-0.083) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.722 (+/-0.083) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.725 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.725 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.725 (+/-0.091) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.119) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.703 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.726 (+/-0.078) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.726 (+/-0.078) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.726 (+/-0.078) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.729 (+/-0.083) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.727 (+/-0.082) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.727 (+/-0.082) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.613 (+/-0.058) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.623 (+/-0.078) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.651 (+/-0.080) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.670 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.670 (+/-0.087) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.685 (+/-0.057) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.717 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.712 (+/-0.090) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.716 (+/-0.092) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.694 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.694 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.694 (+/-0.081) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.643 (+/-0.107) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.594 (+/-0.085) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.614 (+/-0.133) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.619 (+/-0.167) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.619 (+/-0.167) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.643 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.664 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.664 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.586 (+/-0.091) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.590 (+/-0.118) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.624 (+/-0.151) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.645 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.654 (+/-0.106) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.689 (+/-0.038) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.700 (+/-0.123) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.696 (+/-0.113) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.687 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.589 (+/-0.117) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.606 (+/-0.035) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.633 (+/-0.087) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.664 (+/-0.121) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.662 (+/-0.120) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.718 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.703 (+/-0.111) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.702 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.703 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.680 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.694 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.694 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.694 (+/-0.081) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.643 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.594 (+/-0.085) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.614 (+/-0.132) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.620 (+/-0.167) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.666 (+/-0.149) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.628 (+/-0.157) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.666 (+/-0.114) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.664 (+/-0.113) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.664 (+/-0.113) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.543 (+/-0.107) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.562 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.609 (+/-0.154) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.631 (+/-0.158) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.629 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.669 (+/-0.076) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.683 (+/-0.140) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.693 (+/-0.118) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.698 (+/-0.116) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.614 (+/-0.087) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.641 (+/-0.084) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.641 (+/-0.128) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.655 (+/-0.146) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.658 (+/-0.145) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.681 (+/-0.090) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.651 (+/-0.139) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.150) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.659 (+/-0.140) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.694 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.694 (+/-0.096) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.083) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.696 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.696 (+/-0.104) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.698 (+/-0.106) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.669 (+/-0.139) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.669 (+/-0.139) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.139) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.612 (+/-0.097) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.594 (+/-0.125) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.631 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.644 (+/-0.125) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.637 (+/-0.137) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.647 (+/-0.125) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.663 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.664 (+/-0.154) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.666 (+/-0.157) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.740 (+/-0.109) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.710 (+/-0.149) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.714 (+/-0.139) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.646 (+/-0.091) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.648 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.663 (+/-0.110) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.673 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.112) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.678 (+/-0.099) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.682 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.679 (+/-0.140) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.694 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.694 (+/-0.096) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.083) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.696 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.696 (+/-0.104) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.698 (+/-0.106) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.669 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.669 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.610 (+/-0.094) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.600 (+/-0.091) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.631 (+/-0.127) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.637 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.644 (+/-0.133) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.652 (+/-0.095) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.661 (+/-0.132) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.660 (+/-0.133) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.652 (+/-0.136) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.608 (+/-0.112) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.642 (+/-0.080) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.650 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.667 (+/-0.120) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.659 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.675 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.654 (+/-0.145) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.667 (+/-0.135) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.652 (+/-0.141) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.716 (+/-0.127) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.716 (+/-0.127) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.742 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.742 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.742 (+/-0.115) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.694 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.694 (+/-0.096) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.691 (+/-0.083) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.696 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.696 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.698 (+/-0.106) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.669 (+/-0.139) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.669 (+/-0.139) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.669 (+/-0.139) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.612 (+/-0.097) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.609 (+/-0.104) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.632 (+/-0.136) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.637 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.637 (+/-0.124) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.660 (+/-0.112) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.658 (+/-0.153) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.662 (+/-0.155) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.670 (+/-0.158) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.285 (+/-0.118) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.285 (+/-0.144) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.263 (+/-0.237) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.291) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.341 (+/-0.262) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.306) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.352 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.352 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.307 (+/-0.159) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.318 (+/-0.180) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.318 (+/-0.211) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.286 (+/-0.287) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.329 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.318 (+/-0.272) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.186) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.186) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.275 (+/-0.186) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.122) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.252 (+/-0.228) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.291) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.375 (+/-0.281) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.308 (+/-0.290) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.287 (+/-0.183) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.286 (+/-0.230) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.286 (+/-0.270) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.331 (+/-0.285) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.319 (+/-0.305) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.319 (+/-0.305) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.352 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.352 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.307 (+/-0.159) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.285 (+/-0.169) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.329 (+/-0.225) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.286 (+/-0.287) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.329 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.275 (+/-0.292) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.275 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.286 (+/-0.135) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.242 (+/-0.152) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.220 (+/-0.233) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.291) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.364 (+/-0.264) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.306) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.141) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.263 (+/-0.187) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.253 (+/-0.240) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.319 (+/-0.261) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.341 (+/-0.313) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.308 (+/-0.290) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.352 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.352 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.352 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.307 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.307 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.318 (+/-0.211) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.329 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.286 (+/-0.287) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.286 (+/-0.278) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.275 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.275 (+/-0.186) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.275 (+/-0.224) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.230 (+/-0.175) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.228) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.341 (+/-0.313) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.363 (+/-0.308) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.297 (+/-0.306) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.319 (+/-0.194) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.320 (+/-0.221) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.319 (+/-0.251) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.320 (+/-0.221) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.298 (+/-0.222) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.287 (+/-0.251) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.350) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.350) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.353 (+/-0.172) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.275 (+/-0.323) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.275 (+/-0.323) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.364 (+/-0.158) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.375 (+/-0.223) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.320 (+/-0.209) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.276 (+/-0.339) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.319 (+/-0.279) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.319 (+/-0.279) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.319 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.232 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.232 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.232 (+/-0.259) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.166 (+/-0.409) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.297 (+/-0.120) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.287 (+/-0.220) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.287 (+/-0.220) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.309 (+/-0.233) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.287 (+/-0.251) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.298 (+/-0.233) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.298 (+/-0.253) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.242 (+/-0.207) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.350) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.350) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.353 (+/-0.172) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.275 (+/-0.323) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.275 (+/-0.323) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.364 (+/-0.158) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.320 (+/-0.169) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.156) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.276 (+/-0.292) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.319 (+/-0.279) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.319 (+/-0.279) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.340 (+/-0.254) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.232 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.232 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.232 (+/-0.259) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.319 (+/-0.043) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.320 (+/-0.221) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.319 (+/-0.251) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.298 (+/-0.222) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.309 (+/-0.199) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.287 (+/-0.251) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.264 (+/-0.193) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.221 (+/-0.379) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.297 (+/-0.350) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.297 (+/-0.350) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.353 (+/-0.172) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.275 (+/-0.323) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.275 (+/-0.323) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.364 (+/-0.158) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.374 (+/-0.156) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.342 (+/-0.221) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.320 (+/-0.209) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.276 (+/-0.339) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.319 (+/-0.279) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.319 (+/-0.279) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.319 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.232 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.232 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.232 (+/-0.259) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.91       103\n",
      "          1       0.69      0.67      0.68        30\n",
      "\n",
      "avg / total       0.86      0.86      0.86       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.262 (+/-0.058) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.340 (+/-0.151) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.339 (+/-0.211) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.378 (+/-0.176) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.388 (+/-0.124) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.413 (+/-0.247) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.486 (+/-0.275) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.486 (+/-0.275) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.490 (+/-0.263) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.549 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.549 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.549 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.472 (+/-0.215) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.481 (+/-0.257) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.463 (+/-0.187) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.511 (+/-0.254) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.503 (+/-0.241) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.496 (+/-0.209) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.537 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.537 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.537 (+/-0.142) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.444 (+/-0.258) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.362 (+/-0.205) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.373 (+/-0.263) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.456 (+/-0.248) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.477 (+/-0.216) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.413 (+/-0.247) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.486 (+/-0.275) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.486 (+/-0.275) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.486 (+/-0.275) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.150 (+/-0.368) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.150 (+/-0.368) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.150 (+/-0.368) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.554 (+/-0.142) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.554 (+/-0.142) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.554 (+/-0.142) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.525 (+/-0.173) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.534 (+/-0.162) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.534 (+/-0.162) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.525 (+/-0.173) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.534 (+/-0.162) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.534 (+/-0.162) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.545 (+/-0.159) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.370 (+/-0.119) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.378 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.398 (+/-0.221) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.400 (+/-0.233) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.427 (+/-0.227) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.452 (+/-0.160) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.465 (+/-0.228) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.465 (+/-0.228) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.465 (+/-0.228) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.549 (+/-0.126) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.549 (+/-0.126) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.549 (+/-0.126) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.485 (+/-0.186) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.476 (+/-0.225) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.470 (+/-0.199) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.517 (+/-0.206) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.517 (+/-0.206) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.510 (+/-0.183) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.537 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.537 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.537 (+/-0.142) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.437 (+/-0.163) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.359 (+/-0.139) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.337 (+/-0.214) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.452 (+/-0.234) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.458 (+/-0.197) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.431 (+/-0.226) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.490 (+/-0.263) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.490 (+/-0.263) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.490 (+/-0.263) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.342 (+/-0.125) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.349 (+/-0.159) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.374 (+/-0.267) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.373 (+/-0.166) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.398 (+/-0.182) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.431 (+/-0.226) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.486 (+/-0.275) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.486 (+/-0.275) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.490 (+/-0.263) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.515 (+/-0.179) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.549 (+/-0.126) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.549 (+/-0.126) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.549 (+/-0.126) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.472 (+/-0.215) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.475 (+/-0.240) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.477 (+/-0.168) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.511 (+/-0.254) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.511 (+/-0.254) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.496 (+/-0.209) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.537 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.537 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.537 (+/-0.142) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.479 (+/-0.177) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.353 (+/-0.216) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.373 (+/-0.215) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.489 (+/-0.216) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.446 (+/-0.244) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.445 (+/-0.209) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.490 (+/-0.263) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 2}\n",
      "0.490 (+/-0.263) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 10}\n",
      "0.486 (+/-0.275) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'gini', 'min_samples_split': 20}\n",
      "0.331 (+/-0.100) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.351 (+/-0.221) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.377 (+/-0.215) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.375 (+/-0.177) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.387 (+/-0.162) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.411 (+/-0.299) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.426 (+/-0.321) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.429 (+/-0.314) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.426 (+/-0.321) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.340 (+/-0.344) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.340 (+/-0.344) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.478 (+/-0.126) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.361 (+/-0.368) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.361 (+/-0.368) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.498 (+/-0.161) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.504 (+/-0.212) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.504 (+/-0.212) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.504 (+/-0.212) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.425 (+/-0.143) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.400 (+/-0.189) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.370 (+/-0.298) for {'max_depth': None, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.451 (+/-0.204) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.451 (+/-0.204) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.441 (+/-0.227) for {'max_depth': None, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.416 (+/-0.345) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.426 (+/-0.321) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.416 (+/-0.345) for {'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.157 (+/-0.386) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.565 (+/-0.131) for {'max_depth': 2, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.362 (+/-0.196) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.362 (+/-0.196) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.399 (+/-0.196) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.412 (+/-0.170) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.412 (+/-0.170) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.435 (+/-0.231) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.431 (+/-0.246) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.431 (+/-0.246) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.431 (+/-0.246) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.340 (+/-0.344) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.340 (+/-0.344) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.478 (+/-0.126) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.361 (+/-0.368) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.361 (+/-0.368) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.498 (+/-0.161) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.504 (+/-0.212) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.504 (+/-0.212) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.504 (+/-0.212) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.425 (+/-0.066) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.400 (+/-0.114) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.377 (+/-0.294) for {'max_depth': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.418 (+/-0.220) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.418 (+/-0.220) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.452 (+/-0.220) for {'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.426 (+/-0.321) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.416 (+/-0.345) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.416 (+/-0.345) for {'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.336 (+/-0.045) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.356 (+/-0.203) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.363 (+/-0.216) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.394 (+/-0.187) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.390 (+/-0.235) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.411 (+/-0.299) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.429 (+/-0.314) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.426 (+/-0.321) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.429 (+/-0.314) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.268 (+/-0.455) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.340 (+/-0.344) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.340 (+/-0.344) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.478 (+/-0.126) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.361 (+/-0.368) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.361 (+/-0.368) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.498 (+/-0.161) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.504 (+/-0.212) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.504 (+/-0.212) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.504 (+/-0.212) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.436 (+/-0.133) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.400 (+/-0.189) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.370 (+/-0.298) for {'max_depth': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.451 (+/-0.204) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.451 (+/-0.204) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.428 (+/-0.242) for {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "0.426 (+/-0.321) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 2}\n",
      "0.416 (+/-0.345) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 10}\n",
      "0.426 (+/-0.321) for {'max_depth': 10, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decsiontree_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.830 (+/-0.010) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.828 (+/-0.006) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.832 (+/-0.014) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.832 (+/-0.013) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.832 (+/-0.013) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.830 (+/-0.016) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.830 (+/-0.010) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.826 (+/-0.009) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.828 (+/-0.006) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.832 (+/-0.019) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.836 (+/-0.014) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.830 (+/-0.025) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.830 (+/-0.014) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.006) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.828 (+/-0.020) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.832 (+/-0.015) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.830 (+/-0.026) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       103\n",
      "          1       1.00      0.07      0.12        30\n",
      "\n",
      "avg / total       0.83      0.79      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.021 (+/-0.084) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.038 (+/-0.094) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.097 (+/-0.171) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.061 (+/-0.100) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.061 (+/-0.100) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.041 (+/-0.100) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.021 (+/-0.084) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.021 (+/-0.084) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.110 (+/-0.129) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.146 (+/-0.183) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.097 (+/-0.111) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.130 (+/-0.110) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.039 (+/-0.096) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.081 (+/-0.082) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.129 (+/-0.168) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.060 (+/-0.099) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       103\n",
      "          1       1.00      0.07      0.12        30\n",
      "\n",
      "avg / total       0.83      0.79      0.71       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.703 (+/-0.106) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.715 (+/-0.067) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.734 (+/-0.028) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.731 (+/-0.026) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.732 (+/-0.105) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.753 (+/-0.055) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.747 (+/-0.054) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.743 (+/-0.052) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.754 (+/-0.066) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.742 (+/-0.095) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.765 (+/-0.074) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.766 (+/-0.037) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.776 (+/-0.035) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.770 (+/-0.063) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.772 (+/-0.075) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.794 (+/-0.065) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.758 (+/-0.107) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.765 (+/-0.073) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.783 (+/-0.057) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.782 (+/-0.063) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.777 (+/-0.084) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.780 (+/-0.077) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.809 (+/-0.065) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.804 (+/-0.076) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.022 (+/-0.054) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.022 (+/-0.054) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.011 (+/-0.044) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.055 (+/-0.070) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.022 (+/-0.054) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.022 (+/-0.054) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.022 (+/-0.054) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.066 (+/-0.130) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.044 (+/-0.083) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.110 (+/-0.141) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.066 (+/-0.083) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.044 (+/-0.083) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.055 (+/-0.070) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.044 (+/-0.044) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.044 (+/-0.044) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       103\n",
      "          1       1.00      0.20      0.33        30\n",
      "\n",
      "avg / total       0.85      0.82      0.77       133\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.198 (+/-0.798) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.198 (+/-0.798) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.198 (+/-0.798) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 1, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.146 (+/-0.361) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.300 (+/-0.801) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.066 (+/-0.266) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.448 (+/-0.917) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.066 (+/-0.266) for {'max_features': 3, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.000 (+/-0.000) for {'max_features': 3, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "0.607 (+/-0.755) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 1}\n",
      "0.651 (+/-0.872) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 1}\n",
      "0.601 (+/-0.750) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 1}\n",
      "0.559 (+/-0.791) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 1}\n",
      "0.299 (+/-0.798) for {'max_features': 5, 'n_estimators': 50, 'min_samples_leaf': 3}\n",
      "0.665 (+/-0.845) for {'max_features': 5, 'n_estimators': 100, 'min_samples_leaf': 3}\n",
      "0.552 (+/-0.801) for {'max_features': 5, 'n_estimators': 150, 'min_samples_leaf': 3}\n",
      "0.412 (+/-0.776) for {'max_features': 5, 'n_estimators': 200, 'min_samples_leaf': 3}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "randomforest_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
