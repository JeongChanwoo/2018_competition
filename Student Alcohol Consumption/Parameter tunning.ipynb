{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dropped_1 = pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dropped_1 = pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_du_dropped_1= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drop_du_dropped_1= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_du_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drop_du_dropped_2= pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_du_dropped_none_t_3=pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_none_t_3'))\n",
    "train_data_drop_du_dropped_none_t_4=pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_none_t_4'))\n",
    "train_data_drop_du_dropped_none_t_5=pd.DataFrame(pd.read_pickle('./data/PP_data/train_data_drop_du_dropped_none_t_5'))\n",
    "\n",
    "test_data_drop_du_dropped_none_t_3=pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_none_t_3'))\n",
    "test_data_drop_du_dropped_none_t_4=pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_none_t_4'))\n",
    "test_data_drop_du_dropped_none_t_5=pd.DataFrame(pd.read_pickle('./data/PP_data/test_data_drop_du_dropped_none_t_5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "### class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1\n",
    "def logistic_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_logistic = [{'penalty' : ['l2', 'l1'],\n",
    "                      'C' : [1,10,50,100,500,1000]}]\n",
    "    \n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(LogisticRegression(), param_logistic, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Init signature: SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "###shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, \n",
    "###random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "def sgd_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_sgd = {\n",
    "                        'loss': ['log', 'hinge'],\n",
    "                        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                        'alpha': [0.01,0.01,0.001, 0.0001]\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(SGDClassifier(), param_sgd, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "#         print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_knn = {\n",
    "                        'n_neighbors' : [1,3,5,10,30,50], \n",
    "                        'weights' : [\"uniform\", \"distance\"],\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(KNeighborsClassifier(), param_knn, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_nb = {\n",
    "                        'priors' :[None]\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(GaussianNB(), param_nb, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_svc = {\n",
    "                        'C': [0.0001,0.001,0.01,1.0,10.0,100.0],  \n",
    "                        'gamma': ['auto', 0.0001,0.001,0.01,1.0],\n",
    "                        'degree': [1,3,5],  # integer valued parameter\n",
    "                        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(svm.SVC(), param_svc, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsvc_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_lsvc = {\n",
    "                       'C': [0.000001, 0.00001,0.0001,0.001,0.01,1,10,100,1000]\n",
    "                        }\n",
    "\n",
    "    scores = [ 'f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(svm.LinearSVC(max_iter=10000), param_lsvc, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decsiontree_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_dt = {\n",
    "                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "                        \"min_samples_split\": [2, 10, 20],\n",
    "                        \"max_depth\": [None, 2, 5, 10],\n",
    "                        \"min_samples_leaf\": [1, 5, 10],\n",
    "                        \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), param_dt, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest_grid(X_train=None, y_train=None, X_test=None, y_test= None):\n",
    "    param_rt = {\n",
    "                    'criterion': [\"gini\", \"entropy\"],\n",
    "                    'min_samples_split': [2, 10, 20],\n",
    "                    'min_samples_leaf': range(1, 5, 2),\n",
    "#                     'max_depth': [None, 2, 5, 10],\n",
    "                      'max_features': ['auto',1, 3,5,7],\n",
    "#                     'max_leaf_nodes': [None, 5, 10, 20],\n",
    "                      'n_estimators': range(10, 250, 50)\n",
    "                        }\n",
    "\n",
    "    scores = ['f1','roc_auc','recall', 'precision']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = GridSearchCV(RandomForestClassifier(), param_rt, cv=5,\n",
    "        scoring='%s' % score,n_jobs = -1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Best parameters score for %s : \" %score) \n",
    "        print(round(clf.best_score_,3))\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "#         for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#                   % (mean, std * 2, params)) ### 현재는 불필요함 각 파라메타 조합별 결과치\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    print('============================================')\n",
    "#     return clf.cv_results_['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_dropped_1 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# logistic_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sgd_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# knn_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# naivebayes_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# svc_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)\n",
    "\n",
    "# ###상당히 오래걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsvc_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decsiontree_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randomforest_grid(X_train=train_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_dropped_1.iloc[:,-1].values,\n",
    "#              X_test = test_data_dropped_1.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_drop_du_dropped_1 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.64\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.78      0.72        65\n",
      "          1       0.75      0.63      0.69        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.744\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.82      0.74        65\n",
      "          1       0.78      0.63      0.70        68\n",
      "\n",
      "avg / total       0.73      0.72      0.72       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.615\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.78      0.72        65\n",
      "          1       0.75      0.63      0.69        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.683\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.73        65\n",
      "          1       0.77      0.63      0.69        68\n",
      "\n",
      "avg / total       0.72      0.71      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "logistic_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'penalty': 'l1', 'loss': 'hinge'}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.651\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.80      0.76        65\n",
      "          1       0.79      0.71      0.74        68\n",
      "\n",
      "avg / total       0.76      0.75      0.75       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'penalty': 'elasticnet', 'loss': 'log'}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.743\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.97      0.73        65\n",
      "          1       0.92      0.35      0.51        68\n",
      "\n",
      "avg / total       0.76      0.65      0.62       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.001, 'penalty': 'l2', 'loss': 'hinge'}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.799\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.65      0.67        65\n",
      "          1       0.68      0.74      0.71        68\n",
      "\n",
      "avg / total       0.69      0.69      0.69       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.001, 'penalty': 'elasticnet', 'loss': 'hinge'}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.733\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.94      0.72        65\n",
      "          1       0.86      0.37      0.52        68\n",
      "\n",
      "avg / total       0.73      0.65      0.62       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "sgd_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.485\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.68      0.60        65\n",
      "          1       0.59      0.44      0.50        68\n",
      "\n",
      "avg / total       0.56      0.56      0.55       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'distance', 'n_neighbors': 50}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.628\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.91      0.68        65\n",
      "          1       0.76      0.28      0.41        68\n",
      "\n",
      "avg / total       0.66      0.59      0.54       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.47\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.68      0.60        65\n",
      "          1       0.59      0.44      0.50        68\n",
      "\n",
      "avg / total       0.56      0.56      0.55       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 50}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.648\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.91      0.67        65\n",
      "          1       0.74      0.25      0.37        68\n",
      "\n",
      "avg / total       0.64      0.57      0.52       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "knn_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.592\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.75      0.71        65\n",
      "          1       0.73      0.65      0.69        68\n",
      "\n",
      "avg / total       0.70      0.70      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.662\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.75      0.71        65\n",
      "          1       0.73      0.65      0.69        68\n",
      "\n",
      "avg / total       0.70      0.70      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.602\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.75      0.71        65\n",
      "          1       0.73      0.65      0.69        68\n",
      "\n",
      "avg / total       0.70      0.70      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.583\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.75      0.71        65\n",
      "          1       0.73      0.65      0.69        68\n",
      "\n",
      "avg / total       0.70      0.70      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "naivebayes_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.01, 'C': 10.0, 'kernel': 'poly', 'degree': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.646\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.82      0.73        65\n",
      "          1       0.77      0.60      0.68        68\n",
      "\n",
      "avg / total       0.72      0.71      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 10.0, 'kernel': 'poly', 'degree': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.734\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.82      0.73        65\n",
      "          1       0.77      0.60      0.68        68\n",
      "\n",
      "avg / total       0.72      0.71      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 100.0, 'kernel': 'rbf', 'degree': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.624\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.65      0.60        65\n",
      "          1       0.61      0.53      0.57        68\n",
      "\n",
      "avg / total       0.59      0.59      0.59       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 1.0, 'kernel': 'poly', 'degree': 1}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.754\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.91      0.74        65\n",
      "          1       0.84      0.47      0.60        68\n",
      "\n",
      "avg / total       0.73      0.68      0.67       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "svc_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.636\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.78      0.72        65\n",
      "          1       0.75      0.63      0.69        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.737\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.78      0.72        65\n",
      "          1       0.75      0.63      0.69        68\n",
      "\n",
      "avg / total       0.71      0.71      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.607\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.77      0.71        65\n",
      "          1       0.74      0.63      0.68        68\n",
      "\n",
      "avg / total       0.70      0.70      0.70       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.001}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.701\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.91      0.72        65\n",
      "          1       0.82      0.40      0.53        68\n",
      "\n",
      "avg / total       0.71      0.65      0.62       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "lsvc_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 10}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.629\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        65\n",
      "          1       0.76      0.51      0.61        68\n",
      "\n",
      "avg / total       0.69      0.67      0.66       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'max_leaf_nodes': 20, 'criterion': 'entropy', 'min_samples_split': 20, 'min_samples_leaf': 5}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.687\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.85      0.70        65\n",
      "          1       0.75      0.44      0.56        68\n",
      "\n",
      "avg / total       0.67      0.64      0.62       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 5, 'max_leaf_nodes': None, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 10}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.62\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.83      0.71        65\n",
      "          1       0.76      0.51      0.61        68\n",
      "\n",
      "avg / total       0.69      0.67      0.66       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'max_leaf_nodes': 10, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.706\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.83      0.72        65\n",
      "          1       0.77      0.53      0.63        68\n",
      "\n",
      "avg / total       0.70      0.68      0.67       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "decsiontree_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 7, 'criterion': 'entropy', 'n_estimators': 110, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.634\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.80      0.69        65\n",
      "          1       0.73      0.51      0.60        68\n",
      "\n",
      "avg / total       0.67      0.65      0.65       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 5, 'criterion': 'entropy', 'n_estimators': 60, 'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.733\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.82      0.71        65\n",
      "          1       0.75      0.53      0.62        68\n",
      "\n",
      "avg / total       0.69      0.67      0.66       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 7, 'criterion': 'entropy', 'n_estimators': 60, 'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.556\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.85      0.71        65\n",
      "          1       0.76      0.47      0.58        68\n",
      "\n",
      "avg / total       0.68      0.65      0.64       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 1, 'criterion': 'entropy', 'n_estimators': 210, 'min_samples_split': 20, 'min_samples_leaf': 3}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.851\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.94      0.70        65\n",
      "          1       0.83      0.29      0.43        68\n",
      "\n",
      "avg / total       0.70      0.61      0.56       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "randomforest_grid(X_train=train_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_1.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_1.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_1.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_data_drop_du_dropped_2 Grid_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.375\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       103\n",
      "          1       0.80      0.27      0.40        30\n",
      "\n",
      "avg / total       0.82      0.82      0.78       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.754\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       103\n",
      "          1       0.80      0.27      0.40        30\n",
      "\n",
      "avg / total       0.82      0.82      0.78       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.286\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       103\n",
      "          1       0.90      0.30      0.45        30\n",
      "\n",
      "avg / total       0.85      0.83      0.80       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1'}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.564\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       103\n",
      "          1       0.80      0.27      0.40        30\n",
      "\n",
      "avg / total       0.82      0.82      0.78       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "logistic_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.001, 'penalty': 'l1', 'loss': 'hinge'}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.439\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       103\n",
      "          1       0.77      0.33      0.47        30\n",
      "\n",
      "avg / total       0.82      0.83      0.80       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'penalty': 'l2', 'loss': 'log'}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.771\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.98      0.88       103\n",
      "          1       0.67      0.13      0.22        30\n",
      "\n",
      "avg / total       0.77      0.79      0.73       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.001, 'penalty': 'l1', 'loss': 'log'}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.506\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89       103\n",
      "          1       0.67      0.40      0.50        30\n",
      "\n",
      "avg / total       0.80      0.82      0.80       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'penalty': 'l2', 'loss': 'hinge'}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.568\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       103\n",
      "          1       1.00      0.03      0.06        30\n",
      "\n",
      "avg / total       0.83      0.78      0.69       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "sgd_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.169\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       103\n",
      "          1       0.42      0.33      0.37        30\n",
      "\n",
      "avg / total       0.73      0.74      0.73       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 50}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.685\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.142\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       103\n",
      "          1       0.42      0.33      0.37        30\n",
      "\n",
      "avg / total       0.73      0.74      0.73       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.213\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       103\n",
      "          1       0.42      0.33      0.37        30\n",
      "\n",
      "avg / total       0.73      0.74      0.73       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "knn_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.374\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.673\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.438\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'priors': None}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.33\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       103\n",
      "          1       0.45      0.50      0.48        30\n",
      "\n",
      "avg / total       0.76      0.75      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "naivebayes_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 100.0, 'kernel': 'linear', 'degree': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.352\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       103\n",
      "          1       0.82      0.30      0.44        30\n",
      "\n",
      "avg / total       0.83      0.83      0.79       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 0.0001, 'kernel': 'linear', 'degree': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.767\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       103\n",
      "          1       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.60      0.77      0.68       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 100.0, 'kernel': 'rbf', 'degree': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.308\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.85       103\n",
      "          1       0.43      0.30      0.35        30\n",
      "\n",
      "avg / total       0.73      0.75      0.74       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 'auto', 'C': 100.0, 'kernel': 'poly', 'degree': 1}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.521\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       103\n",
      "          1       1.00      0.30      0.46        30\n",
      "\n",
      "avg / total       0.87      0.84      0.81       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "svc_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.379\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89       103\n",
      "          1       0.75      0.30      0.43        30\n",
      "\n",
      "avg / total       0.81      0.82      0.79       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.761\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       103\n",
      "          1       1.00      0.23      0.38        30\n",
      "\n",
      "avg / total       0.86      0.83      0.78       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.395\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       103\n",
      "          1       1.00      0.17      0.29        30\n",
      "\n",
      "avg / total       0.85      0.81      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.533\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89       103\n",
      "          1       0.69      0.37      0.48        30\n",
      "\n",
      "avg / total       0.80      0.82      0.80       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "lsvc_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.43\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': None, 'max_leaf_nodes': 5, 'criterion': 'entropy', 'min_samples_split': 20, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.742\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 10, 'max_leaf_nodes': None, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.407\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.90      0.88       103\n",
      "          1       0.58      0.47      0.52        30\n",
      "\n",
      "avg / total       0.79      0.80      0.80       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 2, 'max_leaf_nodes': 5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.565\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       103\n",
      "          1       0.82      0.60      0.69        30\n",
      "\n",
      "avg / total       0.88      0.88      0.87       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "decsiontree_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'criterion': 'gini', 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "\n",
      "Best parameters score for f1 : \n",
      "0.267\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       103\n",
      "          1       1.00      0.17      0.29        30\n",
      "\n",
      "avg / total       0.85      0.81      0.76       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'criterion': 'gini', 'n_estimators': 60, 'min_samples_split': 20, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for roc_auc : \n",
      "0.81\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       103\n",
      "          1       1.00      0.10      0.18        30\n",
      "\n",
      "avg / total       0.84      0.80      0.73       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'criterion': 'gini', 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "\n",
      "Best parameters score for recall : \n",
      "0.187\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.99      0.88       103\n",
      "          1       0.80      0.13      0.23        30\n",
      "\n",
      "avg / total       0.80      0.80      0.74       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'criterion': 'entropy', 'n_estimators': 60, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "\n",
      "Best parameters score for precision : \n",
      "0.901\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       103\n",
      "          1       1.00      0.07      0.12        30\n",
      "\n",
      "avg / total       0.83      0.79      0.71       133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "randomforest_grid(X_train=train_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_train =train_data_drop_du_dropped_2.iloc[:,-1].values,\n",
    "             X_test = test_data_drop_du_dropped_2.iloc[:,1:-1].values,\n",
    "             y_test = test_data_drop_du_dropped_2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresh hold data grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_drop_du_dropped_none_t_3\n",
    "# train_data_drop_du_dropped_none_t_4\n",
    "# train_data_drop_du_dropped_none_t_5\n",
    "# test_data_drop_du_dropped_none_t_3\n",
    "# test_data_drop_du_dropped_none_t_4\n",
    "# test_data_drop_du_dropped_none_t_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# sgd_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# knn_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# naivebayes_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# svc_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# lsvc_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# decsiontree_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n",
    "\n",
    "# randomforest_grid(X_train=train_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_train =train_data_drop_du_dropped_none_t_3.iloc[:,-1].values,\n",
    "#              X_test = test_data_drop_du_dropped_none_t_3.iloc[:,1:-1].values,\n",
    "#              y_test = test_data_drop_du_dropped_none_t_3.iloc[:,-1].values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
